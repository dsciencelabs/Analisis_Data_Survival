# Database Normalization in SQL

Normalization is a database design technique that reduces data redundancy and eliminates undesirable characteristics like Insertion, Update and Deletion Anomalies. Normalization rules divides larger tables into smaller tables and links them using relationships. The purpose of Normalisation in SQL is to eliminate redundant (repetitive) data and ensure data is stored logically.

The inventor of the relational model Edgar Codd proposed the theory of normalization of data with the introduction of the First Normal Form, and he continued to extend theory with Second and Third Normal Form. Later he joined Raymond F. Boyce to develop the theory of Boyce-Codd Normal Form.

Here is a list of Normal Forms in SQL:

* 1NF (First Normal Form)
* 2NF (Second Normal Form)
* 3NF (Third Normal Form)
* BCNF (Boyce-Codd Normal Form)
* 4NF (Fourth Normal Form)
* 5NF (Fifth Normal Form)
* 6NF (Sixth Normal Form)

The Theory of Data Normalization in MySQL server is still being developed further. For example, there are discussions even on 6th Normal Form. However, in most practical applications, normalization achieves its best in 3rd Normal Form.


## The Process of Normalization

The process of normalization involves breaking down a large table into smaller, related tables and defining relationships between them. This helps in achieving the following benefits:

* **Elimination of Data Redundancy:** Redundant data can lead to inconsistencies and increased storage requirements. Normalization ensures that each piece of data is stored in only one place, reducing redundancy and promoting consistency.
* **Data Integrity:** Normalization minimizes the chances of inconsistencies and anomalies that may occur when data is duplicated or updated in one place but not in another.
* **Efficient Data Updates:** Since data is stored in smaller, more specific tables, updates are more efficient and require fewer changes.
* **Simpler Queries:** Normalized data allows for more straightforward and efficient querying due to the structured relationships between tables.

The process of database normalization is typically divided into several "normal forms" (often referred to as 1NF, 2NF, 3NF, BCNF, etc.), each with its own set of rules and requirements. These normal forms build on each other, with higher normal forms addressing more complex issues of redundancy and dependency. Here's a brief overview of some common normal forms:

1. **First Normal Form (1NF):**
  * Eliminate duplicate columns.
  * Create separate tables for related data.
  * Define a primary key for each table.
2. **Second Normal Form (2NF):**
  * Meet 1NF requirements.
  * Remove partial dependencies (attributes dependent on only part of the primary key) by creating
  * separate tables.
3. **Third Normal Form (3NF):**
  * Meet 2NF requirements.
  * Remove transitive dependencies (attributes dependent on non-key attributes) by creating separate tables.
4. **Boyce-Codd Normal Form (BCNF):**
  * Meet 3NF requirements.
  * Remove overlapping candidate keys by creating separate tables.

Higher normal forms exist beyond these, such as **Fourth Normal Form (4NF)** and **Fifth Normal Form (5NF)**, but they are less commonly encountered and may be more relevant in specific cases of complex data modeling. While normalization offers significant benefits, it's important to strike a balance between normalization and performance. Over-normalization can lead to complex query logic and decreased query performance. Therefore, designing a database often involves considering the nature of the data and the queries that will be performed on it.

## Simple Database Normalization

Let's go through a simple example of database normalization using a hypothetical scenario of an online bookstore. We'll start with an unnormalized table and then progressively normalize it through different normal forms.

Scenario: Consider an unnormalized table that stores information about books, authors, and their publishers.

**Unnormalized Table (1NF):**

| Book ID | Title           | Author       | Author Birth | Publisher   | Year |
|---------|-----------------|--------------|--------------|-------------|------|
| 1       | Algorithm       | John Smith   | 1980-05-15   | ABC Pub     | 2000 |
| 2       | Data Science    | Jane Doe     | 1975-10-20   | XYZ Books   | 2015 |
| 3       | Database System | John Smith   | 1980-05-15   | ABC Pub     | 2012 |

In this unnormalized table, we have duplicate author and publisher information, leading to redundancy. John Smith's information is repeated, and if any of his details change, we need to update multiple rows.

**First Normal Form (1NF):**

To achieve 1NF, we break the table into smaller tables and remove duplicate data. We create separate tables for authors and publishers.

Authors Table:

| Author ID | Author       | Author Birth |
|-----------|--------------|--------------|
| 1         | John Smith   | 1980-05-15   |
| 2         | Jane Doe     | 1975-10-20   |

Publishers Table:

| Publisher ID | Publisher   |
|--------------|-------------|
| 1            | ABC Pub     |
| 2            | XYZ Books   |

Books Table (1NF):

| Book ID | Title           | Author ID | Publisher ID | Year |
|---------|-----------------|-----------|--------------|------|
| 1       | Algorithm       | 1         | 1            | 2000 |
| 2       | Data Science    | 2         | 2            | 2015 |
| 3       | Database System | 1         | 1            | 2012 |

We've eliminated redundancy by referencing author and publisher IDs in the books table.

**Second Normal Form (2NF):**

To achieve 2NF, we identify partial dependencies and create a separate table for author information.

Authors Table (2NF):

| Author ID | Author       | Author Birth |
|-----------|--------------|--------------|
| 1         | John Smith   | 1980-05-15   |
| 2         | Jane Doe     | 1975-10-20   |

Books Table (2NF):

| Book ID | Title           | Author ID | Publisher ID | Year |
|---------|-----------------|-----------|--------------|------|
| 1       | Algorithm       | 1         | 1            | 2000 |
| 2       | Data Science    | 2         | 2            | 2015 |
| 3       | Database System | 1         | 1            | 2012 |
No changes are required in the Books table for 2NF since there were no partial dependencies.

**Third Normal Form (3NF):**

To achieve 3NF, we identify transitive dependencies and create a separate table for publisher information.

Publishers Table (3NF):

| Publisher ID | Publisher   |
|--------------|-------------|
| 1            | ABC Pub     |
| 2            | XYZ Books   |

Books Table (3NF):

| Book ID | Title           | Author ID | Publisher ID | Year |
|---------|-----------------|-----------|--------------|------|
| 1       | Algorithm       | 1         | 1            | 2000 |
| 2       | Data Science    | 2         | 2            | 2015 |
| 3       | Database System | 1         | 1            | 2012 |

No changes are required in the Books table for 3NF since there were no transitive dependencies. The result is a normalized database structure that eliminates redundancy and ensures data integrity.

Please note that the above example is simplified for demonstration purposes. In real-world scenarios, databases can have more complex structures and relationships, which may require deeper levels of normalization to achieve higher normal forms like BCNF or 4NF.

## Your Job

Consider a hypothetical database for an online bookstore. We'll start with a denormalized table and then go through the normalization process step by step.

Suppose we have a single table called Books with the following columns:

```{r, echo=FALSE}
BookID = c(1,2,3)
Title = c("Book A", "Book B","Book B")
Author = c("Author X", "Author Y","Author X")
Genre = c("Fiction", "Mystery","Romance")
Publisher =  c("dsciencelabs", "Matana","dsciencelabs")
PublicationYear = c(2021, 2022,2023)

df1 = as.data.frame(cbind(BookID, Title, Author, Genre, Publisher, PublicationYear))

knitr::kable(df1, caption = "First Normal Form (1NF)")
```


Your job is the following statements:

1. Display Database Normalization Process
2. Create Database to your PC After Normalization Process using R and SQL


