<style>
body{
text-align: justify}
</style>

# Aljabar Linier {#linearaljabar}

Pada *chapter* ini penulis akan menjelaskan mengenai cara untuk menyelesaikan sistem persamaan linier. Adapun yang akan dibahas pada *chapter* ini antara lain:

* operasi Vektor dan matriks
* Metode Eliminasi Gauss
* Metode Dekomposisi matriks
* Studi Kasus

## Vektor dan matriks {#vecmat}

Pada Chapter \@ref(vector) dan Chapter \@ref(matriks) telah dijelaskan sekilas bagaimana cara melakukan operasi pada vektor dan matriks. Pada *chapter* ini, penulis akan menambahkan operasi-operasi lain yang dapat dilakukan pada vektor dan matriks. Dasar-dasar operasi ini selanjutnya akan digunakan sebagai dasar menyusun algoritma penyelesaian sistem persamaan linier.

### Operasi Vektor {#operasivektor}

Misalkan saja diberikan vektor $u$ dan $v$ yang ditunjukkan pada Persamaan \@ref(eq:vectoruv).

\begin{equation}
u = \begin{bmatrix}
      u_1            \\[0.3em]
      u_2            \\[0.3em]
      \vdots         \\[0.3em] 
      u_n
     \end{bmatrix}
dan\ v\ = \begin{bmatrix}
      v_1            \\[0.3em]
      v_2            \\[0.3em]
      \vdots         \\[0.3em] 
      v_n
     \end{bmatrix}
  (\#eq:vectoruv)
\end{equation}

Jika kita menambahkan atau mengurangkan nilai elemen vektor dengan suatu skalar (konstanta yang hanya memiliki besaran), maka operasi penjumlahan/pengurangan akan dilakukan pada setiap elemen vektor. 

\begin{equation}
u \pm x = \begin{bmatrix}
      u_1            \\[0.3em]
      u_2            \\[0.3em]
      \vdots         \\[0.3em] 
      u_n
     \end{bmatrix}
\pm x = \begin{bmatrix}
      u_1 \pm x            \\[0.3em]
      u_2 \pm x           \\[0.3em]
      \vdots         \\[0.3em] 
      u_n \pm x
     \end{bmatrix}
     (\#eq:addvector)
\end{equation}

Jika kita melakukan penjumlahan pada vektor $u$ dan $v$, maka operasi akan terjadi pada masing-masing elemen dengan indeks yang sama.

\begin{equation}
u \pm v = \begin{bmatrix}
      u_1            \\[0.3em]
      u_2            \\[0.3em]
      \vdots         \\[0.3em] 
      u_n
     \end{bmatrix}
\pm v\ = \begin{bmatrix}
      v_1            \\[0.3em]
      v_2            \\[0.3em]
      \vdots         \\[0.3em] 
      v_n
     \end{bmatrix}
= \begin{bmatrix}
      u_1 \pm v_1            \\[0.3em]
      u_2 \pm v_2           \\[0.3em]
      \vdots         \\[0.3em] 
      u_n \pm v_n
     \end{bmatrix}
     (\#eq:addvector2)
\end{equation}

Untuk lebih memahami operasi tersebut, berikut penulis berikan contoh penerapannya pada `R`:

```{r}
u <- seq(1,5)
v <- seq(6,10)

# penjumlahan
u+v

# penguranga
u-v
```

Bagaimana jika kita melakukan operasi dua vektor, dimaana salah satu vektor memiliki penjang yang berbeda?. Untuk memnjawab hal tersebut, perhatikan sintaks berikut:

```{r}
x <- seq(1,2)
u+x

```

Berdasarkan contoh tersebut, `R` akan mengeluarkan peringatan yang menunjukkan operasi dilakukan pada vektor dengan panjang berbeda. `R` akan tetap melakukan perhitungan dengan menjumlahkan kembali vektor $u$ yang belum dijumlahkan dengan vektor $x$ sampai seluruh elemen vektor $u$ dilakukan operasi penjumlahan.

Operasi lain yang dapat dilakukan pada vektor adalah menghitung *inner product* dan panjang vektor. Inner product dihitung menggunakan Persamaan \@ref(eq:innerproduct).

\begin{equation}
u.v=\sum_{i=1}^nu_1v_1+u_2v_2+\dots+u_nv_n
  (\#eq:innerproduct)
\end{equation}

Panjang vektor atau vektor yang telah dinormalisasi dihitung menggunakan Persamaan \@ref(eq:panjangvektor)

\begin{equation}
\left|u\right|=\sqrt{u_1^2+u_2^2+\dots+u_n^2}
  (\#eq:panjangvektor)
\end{equation}

Berikut adalah contoh bagaimana cara menghitung `inner product` dan panjang vektor menggunakan `R`:

```{r}
# inner product
u%*%v

# panjang vektor u
sqrt(sum(u*u))
```


### Operasi matriks {#operasimatrik}

Misalkan kita memiliki 2 buah matriks $A$ dan $B$.

\begin{equation}
A = \begin{bmatrix}
       a_{1.1} & a_{1.2} &\cdots& a_{1.n}           \\[0.3em]
       a_{2.1} & a_{2.2} &\cdots& a_{2.n}           \\[0.3em]
       \vdots  & \vdots  &\ddots& \vdots            \\[0.3em]
       a_{m.1} & a_{m.2} &\cdots& a_{m.n}
     \end{bmatrix}
dan\ B = \begin{bmatrix}
      b_{1.1} & b_{1.2} &\cdots& b_{1.n}           \\[0.3em]
      b_{2.1} & b_{2.2} &\cdots& b_{2.n}           \\[0.3em]
      \vdots  & \vdots  &\ddots& \vdots            \\[0.3em]
      b_{m.1} & b_{m.2} &\cdots& b_{m.n}
     \end{bmatrix}
  (\#eq:matrikuv)
\end{equation}

Jika salah satu matriks tersebut dijumlahkan atau dikurangkan dengan skalar.

\begin{equation}
A \pm x = \begin{bmatrix}
       a_{1.1} & a_{1.2} &\cdots& a_{1.n}           \\[0.3em]
       a_{2.1} & a_{2.2} &\cdots& a_{2.n}           \\[0.3em]
       \vdots  & \vdots  &\ddots& \vdots            \\[0.3em]
       a_{m.1} & a_{m.2} &\cdots& a_{m.n}
     \end{bmatrix}
\pm x = \begin{bmatrix}
      a_{1.1}\pm x & a_{1.2}\pm x &\cdots& a_{1.n}\pm x           \\[0.3em]
      a_{2.1}\pm x & a_{2.2}\pm x &\cdots& a_{2.n}\pm x           \\[0.3em]
      \vdots  & \vdots  &\ddots& \vdots            \\[0.3em]
      a_{m.1}\pm x & a_{m.2}\pm x &\cdots& a_{m.n}\pm x
     \end{bmatrix}
  (\#eq:addmatrik)
\end{equation}

Jika kedua matriks $A$ dan $B$ saling dijumlahkan atau dikurangkan. Perlu diperhatikan bahwa penjumlahan dua buah matriks hanya dapat dilakukan pada matriks dengan ukuran yang seragam.

\begin{equation}
\begin{split}
A \pm B & = \begin{bmatrix}
       a_{1.1} & a_{1.2} &\cdots& a_{1.n}           \\[0.3em]
       a_{2.1} & a_{2.2} &\cdots& a_{2.n}           \\[0.3em]
       \vdots  & \vdots  &\ddots& \vdots            \\[0.3em]
       a_{m.1} & a_{m.2} &\cdots& a_{m.n}
     \end{bmatrix}
\pm \begin{bmatrix}
      b_{1.1} & b_{1.2} &\cdots& b_{1.n}           \\[0.3em]
      b_{2.1} & b_{2.2} &\cdots& b_{2.n}           \\[0.3em]
      \vdots  & \vdots  &\ddots& \vdots            \\[0.3em]
      b_{m.1} & b_{m.2} &\cdots& b_{m.n}
     \end{bmatrix} \\
& = \begin{bmatrix}
       a_{1.1}\pm b_{1.1} & a_{1.2}\pm b_{1.2} &\cdots& a_{1.n}\pm b_{1.n}           \\[0.3em]
       a_{2.1}\pm b_{2.1} & a_{2.2}\pm b_{2.2} &\cdots& a_{2.n}\pm b_{2.n}           \\[0.3em]
       \vdots  & \vdots  &\ddots& \vdots            \\[0.3em]
       a_{m.1}\pm b_{m.1} & a_{m.2}\pm b_{m.2} &\cdots& a_{m.n}\pm b_{m.n}
     \end{bmatrix}
\end{split}
  (\#eq:addmatrik2)
\end{equation}

Untuk lebih memahaminya, berikut disajikan contoh operasi penjumlahan pada matriks:

```{r}
A <- matrix(1:9,3)
B <- matrix(10:18,3)
C <- matrix(1:6,3)

# penjumlahan dengan skalar
A+1

# penjumlahan A+B
A+B
```

```{r, eval=FALSE}
# penjumlahan
A+C
```

Operasi pehitungan lain yang penting pada matriks adalah operasi perkalian matriks. Perlu diperhatikan bahwa untuk perkalian matriks, jumlah kolom matriks sebelah kiri harus sama dengan jumlah baris pada matriks sebelah kanan. Perkalian antara dua matriks disajikan pada Persamaan \@ref(eq:kalimatrik).

\begin{equation}
A_{m.n}\times B_{n.r}=AB_{m.r}
  (\#eq:kalimatrik)
\end{equation}

Pada `R` perkalian matriks dilakukan menggunakan operator `%*%`. Berikut adalah contoh perkalian matriks pada `R`:

```{r}
# Perkalian matriks
A%*%B
```

## Operasi Baris Elementer {#rowoperation}

Terdapat tiga buah operasi dasar pada baris matriksoperasi baris elementer. Ketiga operasi ini akan menjadi dasar operasi *sub-chapter* selanjutnya. Ketiga operasi dasar tersebut antara lain:

1. **_Row Scalling_**. Mengalikan baris matriks dengan konstanta bukan nol.
2. **_Row Swaping_**. Menukar urutan baris pada sebuah matriks (contoh: menukar baris 1 dengan baris 2 dan sebaliknya).
3. **_Row Replacement_**. Baris matriks diganti dengan hasil penjumlahan atau pengurangan baris matriks tersebut dengan baris matriks lainnya, dimana baris matriks lainnya yang akan dijumlahkan/dikurangkan dengan matriks tersebut telah dilakukan proses *row scalling*. Luaran yang diperoleh pada umumnya adalah nilai nol pada baris matriks awal atau akhir.

Ketiga proses tersebut akan terjadi secara berulang, khusunya jika kita hendak mengerjakan sistem persamaan linier menggunakan algoritma eliminasi Gauss. Untuk mempermudah proses tersebut, kita dapat membuat masing-masing fungsi untuk masing-masing operasi tersebut. Algoritma fungsi-fungsi tersebut selanjutnya menjadi dasar penyusunan algoritma fungsi-fungsi eliminasi Gauss dan dekomposisi matriks yang akan dijelaskan pada *chapter* selanjutnya.

Fungsi *row scalling* pada `R` dapat dituliskan pada sintaks berikut:

```{r}
scale_row <- function(m, row, k){
 m[row, ] <- m[row, ]*k
 return(m)
}
```

Berikut adalah contoh penerapannya:

```{r}
# membuat matriks A
(A <- matrix(1:15, nrow=5))

# lakukan scaling pada row 2 dengan nilai 10
scale_row(m=A, row=2, 10)
```

> **Catatan:** Untuk menyimpan hasil perhitungan, simpan proses perhitungan dalam sebuah objek (lihat Chapter \@ref(assigningvar)).

*Row swapping* merupakan proses yang berulang, kita perlu menyimpan terlebih dahulu baris matriks pertama kedalam sebuah objek. Baris matriks pertama selanjutnya diganti dengan baris matriks kedua, sedangkan baris matriks kedua selanjutnya akan diganti dengan baris matriks pertama yang telah terlebih dahulu disimpan dalam sebuah objek. Fungsi *row swapping* pada `R` dapat dituliskan pada sintaks berikut:

```{r}
swap_row <- function(m, row1, row2){
  row_tmp <- m[row1, ]
  m[row1, ] <- m[row2, ]
  m[row2, ] <- row_tmp
  return(m)
}
```

Berikut merupakan contoh penerapan fungsi `swap_row()`:

```{r}
# pertukarkan baris 2 dengan baris 5
swap_row(m=A, row1=2, row2=5)
```

Pada proses *row replacement*, proses perhitungan dilakukan dengan melakukan penjumlahan suatu baris matriks dengan baris matriks lainnya dengan terlebih dahulu melakukan *row scalling* terhadap matriks lainnya. Berikut adalah fungsi `replace_row()` yang ditulis pada `R`:

```{r}
replace_row <- function(m, row1, row2, k){
  m[row2, ] <- m[row2, ] + m[row1, ]*k
  return(m)
}
```

Berikut adalah contoh penerapan fungsi `replace_row()`:

```{r}
replace_row(m=A, row1=1, row2=3, k=-3)
```

## Eliminasi Gauss {#gausselimination}

Pada *sub-chapter* ini kita akan menggunakan operasi baris elementer yang telah dijelaskan pada Chapter \@ref(assigningvar). Terdapat dua topik yang akan dibahas pada *sub-chapter* ini, yaitu: *row echelon form* termasuk *reduced row echelon form* dan matriks tridiagonal.

Eliminasi Gauss merupakan sebuah cara untuk mencari penyelesaian sistem persamaan linier. Ide dasar dari eliminasi Gauss adalah melakukan operasi matematika pada baris matriks (lihat Chapter \@ref(assigningvar)) dan melanjutkannya sampai hanya tersisa satu variabel saja. Kita dapat melakukan lebih dari satu operasi baris elementer pada proses elmininasi ini (contoh: mengalikan sebuah baris dengan konstanta dan menjumlahkan hasilnya pada baris lain).

### *Row Echelon Form* {#rowechelonform}

Sebuah matriks merupakan *row echelon form* jika matriks tersebut memenuhi beberapa kondisi:

1. Angka bukan nol pertama dari kiri (*leading coefficient*) selalu di sebelah kanan angka bukan nol pertama pada baris di atasnya.
2. Baris yang terdiri dari semua nol ada di bagian bawah matriks.

Misalkan terdapat persamaan linier seperti yang ditunjukkan pada Persamaan \@ref(eq:spl).

\begin{equation}
\begin{matrix}
  a_{1.1}x_1+a_{1.2}x_2+a_{1.3}x_3+\cdots+a_{1.n}x_n=b_1 \\
  a_{2.1}x_1+a_{2.2}x_2+a_{2.3}x_3+\cdots+a_{2.n}x_n=b_2 \\
  a_{3.1}x_1+a_{3.2}x_2+a_{3.3}x_3+\cdots+a_{3.n}x_n=b_3 \\
  \cdots\cdots\cdots\cdots\cdots\cdots\cdots\cdots       \\
  a_{m.1}x_1+a_{m.2}x_2+a_{m.3}x_3+\cdots+a_{m.n}x_n=b_n
 \end{matrix}
  (\#eq:spl)
\end{equation}

dimana $a_{i.j}$ untuk $i=1$ sampai dengan $m$ dan $j=1$ sampai dengan $n$ merupakan koefisien persamaan linier. $x_i$ untuk $i=1$ sampai dengan $n$ merupakan variabel bebas pada sistem persamaan linier.

Persamaan linier pada Persamaan \@ref(eq:spl) dapat dinyatakan ke dalam bentuk matriks pada Persamaan \@ref(eq:matrikpl).

\begin{equation}
\begin{bmatrix}
     a_{1.1} & a_{1.2} & a_{1.3} &\cdots& a_{1.n}           \\[0.3em]
     a_{2.1} & a_{2.2} & a_{2.3} &\cdots& a_{2.n}           \\[0.3em]
     a_{3.1} & a_{3.2} & a_{3.3} &\cdots& a_{3.n}           \\[0.3em]
     \vdots  & \vdots  & \vdots  &\ddots& \vdots            \\[0.3em]
     a_{m.1} & a_{m.2} & a_{m.3} &\cdots& a_{m.n}
     \end{bmatrix}
\begin{bmatrix}
     x_1                                          \\[0.3em]
     x_2                                          \\[0.3em]
     x_3                                          \\[0.3em]
     \cdots                                       \\[0.3em]
     x_n                                       
     \end{bmatrix}
= \begin{bmatrix}
     b_1                                          \\[0.3em]
     b_2                                          \\[0.3em]
     b_3                                          \\[0.3em]
     \cdots                                       \\[0.3em]
     b_n                                       
     \end{bmatrix}
  (\#eq:matrikpl)
\end{equation}

\begin{equation}
AX=B
  (\#eq:matrikpl2)
\end{equation}

dimana:

- matriks A merupakan matriks koefisien / Jacobian
- vaktor X merupakan vaktor variabel
- vektor B merupakan vektor konstanta

matriks pada Persamaan \@ref(eq:matrikpl) dapat diubah menjadi *augmented matrix*, yaitu: perluasan matriks A dengan menambahkan vektor B pada kolom terakhirnya.

\begin{equation}
\begin{bmatrix}
     a_{1.1} & a_{1.2} & a_{1.3} &\cdots& a_{1.n} & b_1     \\[0.3em]
     a_{2.1} & a_{2.2} & a_{2.3} &\cdots& a_{2.n} & b_2     \\[0.3em]
     a_{3.1} & a_{3.2} & a_{3.3} &\cdots& a_{3.n} & b_3     \\[0.3em]
     \vdots  & \vdots  & \vdots &\ddots& \vdots            \\[0.3em]
     a_{m.1} & a_{m.2} & a_{m.3} &\cdots& a_{m.n} & b_n
     \end{bmatrix}
  (\#eq:augmatrik)
\end{equation}

\begin{equation}
A=\left[A|B\right]
  (\#eq:augmatrik2)
\end{equation}

```{theorem, name="spltheorem"}
Suatu sistem persamaan linier mempunyai penyelesaian tunggal bila memenuhi syarat-syarat sebagai berikut:
```

- ukuran persamaan linier simultan bujursangkar (jumlah persamaan sama dengan jumlah variabel bebas).
- sistem persamaan linier *non-homogen* di mana minimal ada satu nilai vektor konstanta $B$ tidak nol atau terdapat $b_{n}\neq 0$.
- Determinan dari matriks koefisiensistem persamaan linier tidak sama dengan nol.


Untuk memperoleh penyelesaian sistem persamaan linier, Persamaan \@ref(eq:augmatrik) perlu dilakukan operasi baris elementer. Hasil operasi baris dasar akan menghasilkan matriks *row echelon form* yang disajikan pada Persamaan \@ref(eq:refeq).

\begin{equation}
\begin{bmatrix}
     a_{1.1} & a_{1.2} & a_{1.3} &\cdots& a_{1.n} & b_1     \\[0.3em]
     a_{2.1} & a_{2.2} & a_{2.3} &\cdots& a_{2.n} & b_2     \\[0.3em]
     a_{3.1} & a_{3.2} & a_{3.3} &\cdots& a_{3.n} & b_3     \\[0.3em]
     \vdots  & \vdots  & \vdots &\ddots& \vdots             \\[0.3em]
     a_{m.1} & a_{m.2} & a_{m.3} &\cdots& a_{m.n} & b_n
     \end{bmatrix}
\implies
\begin{bmatrix}
     c_{1.1} & c_{1.2} & c_{1.3} &\cdots& c_{1.n} & d_1     \\[0.3em]
     0       & c_{2.2} & c_{2.3} &\cdots& c_{2.n} & d_2     \\[0.3em]
     0       & 0       & c_{3.3} &\cdots& c_{3.n} & d_3     \\[0.3em]
     \vdots  & \vdots  & \vdots &\ddots& \vdots             \\[0.3em]
     0       & 0       & 0      &\cdots& c_{m.n} & d_n
     \end{bmatrix}
  (\#eq:refeq)
\end{equation}

Sehingga penyelesaian sistem persamaan linier dapat diperoleh menggunakan Persamaan \@ref(eq:refsolution).

\begin{equation}
\begin{matrix}
  x_n=\frac{d_n}{c_{m.n}} \\
  x_{n-1}=\frac{1}{C_{m-1.n-1}}\left(d_{n-1}-c_{m-1.n}x_n\right) \\
  \cdots\cdots\cdots\cdots\cdots\cdots\cdots\cdots       \\
  x_2=\frac{1}{c_{2.2}}\left(d_2-c_{2.3}x_3-c_{2.4}x_4-\dots-c_{2.n}x_n\right) \\
  x_1=\frac{1}{c_{1.1}}\left(d_1-c_{1.2}x_2-c_{1.3}x_3-\dots-c_{1.n}x_n\right)
   \end{matrix}
  (\#eq:refsolution)
\end{equation}

```{example, refexm}
Selesaikan sistem persamaan berikut:
```

$$
\begin{matrix}
  x_1+x_2+x_3=6 \\
  x_1+2x_2-x_3=2 \\
  2x_1+x_2+2x_3=10 \\
\end{matrix}
$$

**Jawab**:

*Augmented matrix* sistem persamaan linier tersebut adalah sebagai berikut:

$$
\begin{bmatrix}
     1 & 1 & 1 & 6     \\[0.3em]
     1 & 2 & -1 & 2     \\[0.3em]
     2 & 1 & 2 & 10
\end{bmatrix}
$$

Operasi baris elementer selanjutnya dilakukan pada matriks tersebut. Pada langkah pertama, baris ke-2 dikurangkan dengan baris ke-1 ($B_2-B_1$) dan baris ke-3 dikurangkan oleh dua kali baris ke-1 ($B_3-2B_1$).

\begin{equation*}
\begin{bmatrix}
     1 & 1 & 1 & 6     \\[0.3em]
     1 & 2 & -1 & 2     \\[0.3em]
     2 & 1 & 2 & 10
\end{bmatrix}
\begin{matrix}
  B_2-B_1 \\
  \implies \\
  B_3-2B_1
\end{matrix}
\begin{bmatrix}
     1 & 1 & 1 & 6     \\[0.3em]
     0 & 1 & -2 & -4     \\[0.3em]
     0 & -1 & 0 & -2
\end{bmatrix}
\end{equation*}

Hasil dari langkah pertama tersebut, selanjutnya menjadi input dari langkah selanjutnya. Pada langkah selanjutnya operasi baris elementer kembali dilanjutkan. Baris ke-3 dikurangkan denganbaris ke-2 ($B_3-B_2$).

\begin{equation*}
\begin{bmatrix}
     1 & 1 & 1 & 6     \\[0.3em]
     0 & 1 & -2 & -4     \\[0.3em]
     0 & -1 & 0 & -2
\end{bmatrix}
\begin{matrix}
  B_3-B_2 \\
  \implies
\end{matrix}
\begin{bmatrix}
     1 & 1 & 1 & 6     \\[0.3em]
     0 & 1 & -2 & -4     \\[0.3em]
     0 & 0 & -2 & -6
\end{bmatrix}
\end{equation*}


Setelah diperoleh matriks *row echelon form* selanjutnya penyelesaian persamaan dapat dikerjakan menggunakan Persamaan \@ref(eq:refsolution).

\begin{equation*}
\begin{matrix}
  x_3=\frac{-6}{-2}=3 \\
  x_2=\frac{1}{1}\left(-4-\left(2\right)3\right)=2 \\
  x_1=\frac{1}{1}\left(6-2-3\right)=1
\end{matrix}
\end{equation*}

-------------------------------------

**Algoritma Row Echelon Form**


1. Masukkan matriks $A$, dan vektor $B$ beserta ukurannya $n$
2. Buat *augmented matrix* $\left[A|B\right]$ namakan dengan $A$
3. Untuk baris ke-$i$ dimana $i=1$ s/d $n$, perhatikan apakah nilai $a_{i,j}$ sama dengan nol. **a)** **Bila iya**, lakukan *row swapping* antara baris ke-$i$ dan baris ke-$i+k\leq n$, dimana $a_{i+k,j}$ tidak sama dengan nol. Bila tidak ada berarti perhitungan tidak bisa dilanjutkan dan proses dihentikan dengan tanpa penyelesaian, **b)** **Bila tidak**, lanjutkan.
4. Untuk baris ke-$j$, dimana $j=i+1$ s/d $n$, lakukan operasi baris elementer:**a)** Hitung $c=\frac{a_{j,i}}{a_{i,i}}$, **b)** untuk kolom $k$, dimana $k=1$ s/d $n+1$, hitung $a_{j,k}=a_{j,k}-c.a_{i,k}$.
5. Hitung akar, untuk $i=n$ s/d 1 (bergerak dari baris pertama) menggunakan Persamaan \@ref(eq:refsolution). 

--------------------------------

Berdasarkan algoritma tersebut, kita dapat menyusun fungsi pada `R` untuk menyelesaikan sistem persamaan linier menggunakan matriks *row echelon form*. Fungsi yang akan dibentuk hanya sampai pada algoritma ke-4. Proses substitusi akan dilakukan secara manual. Berikut adalah sintaks yang digunakan:

```{r}
ref_matrix <- function(a){
  m <- nrow(a)
  n <- ncol(a)
  piv <- 1
  
# cek elemen diagonal apakah bernilai nol
  for(row_curr in 1:m){
    if(piv <= n){
      i <- row_curr
      while(a[i, piv] == 0 && i < m){
        i <- i+1
        if(i > m){
          i <- row_curr
          piv <- piv+1
          if(piv > n)
            return(a)
        }
      }
      
# jika diagonal bernilai nol, lakukan row swapping
    if(i != row_curr)
      a <- swap_row(a, i, row_curr)
    
# proses triangulasi untuk membentuk matriks segitiga atas
    for(j in row_curr:m)
      if(j != row_curr){
        c <- a[j, piv]/a[row_curr, piv]
        a <- replace_row(a, row_curr, j, -c)
      }
    piv <- piv+1
    }
  }
  return(a)
}
      
```

Dengan menggunakan fungsi `ref_matrix()`, kita dapat membentuk matriks *row echelon form* pada Contoh \@ref(exm:refexm).

```{r}
am <- c(1,1,2,
        1,2,1,
        1,-1,2,
        6,2,10)
(m <- matrix(am, nrow=3))

ref_matrix(m)
```

matriks yang diperoleh selanjutnya dapat diselesaikan menggunakan Persamaan \@ref(eq:refsolution).

```{example, refexm2}
Dengan menggunakan fungsi `ref_matrix()`, buatlah matriks *row echelon form* dari sistem persamaan linier berikut:
```

$$
\begin{matrix}
  2x_1+x_2-x_3=1 \\
  3x_1+2x_2-2x_3=1 \\
  x_1-5x_2+4x_3=3 \\
\end{matrix}
$$

**Jawab**:

*Augmented matrix* dari sistem persamaan tersebut adalah sebagai berikut:

$$
\begin{bmatrix}
     2 & 1 & -1 & 1     \\[0.3em]
     3 & 2 & -2 & 1     \\[0.3em]
     1 & -5 & 4 & 3
\end{bmatrix}
$$

Penyelesaian matriks tersebut adalah sebagai berikut:

```{r}
(m <- matrix(c(2,3,1,
              1,2,-5,
              -1,-2,4,
              1,1,3), nrow=3))
ref_matrix(m)
```

Proses lebih lanjut akan menghasilkan penyelesaian sebagai berikut:

$$
\begin{matrix}
     x_1=1     \\[0.3em]
     x_2=2     \\[0.3em]
     x_3=3
\end{matrix}
$$

### Eliminasi Gauss-Jordan {#redrowechelonform}

Berbeda dengan metode eliminasi Gauss yang telah dijelaskan pada Chapter \@ref(rowechelonform), metode eliminasi Gauss-Jordan membentuk matriks menjadi bentuk *reduced row echelon form*. Metode ini merupakan pengembangan metode eliminasi Gauss, dimana matriks sebelah kiri *augmented matrix* diubah menjadi matriks diagonal (lihat Persamaan \@ref(eq:gaussjordan)).

\begin{equation}
\begin{bmatrix}
     a_{1,1} & a_{1,2} & a_{1,3} &\cdots& a_{1,n} & b_1     \\[0.3em]
     a_{2,1} & a_{2,2} & a_{2,3} &\cdots& a_{2,n} & b_2     \\[0.3em]
     a_{3,1} & a_{3,2} & a_{3,3} &\cdots& a_{3,n} & b_3     \\[0.3em]
     \vdots  & \vdots  & \vdots &\ddots& \vdots             \\[0.3em]
     a_{m,1} & a_{m,2} & a_{m,3} &\cdots& a_{m,n} & b_n
     \end{bmatrix}
\implies
\begin{bmatrix}
     1       & 0       & 0       &\cdots& 0       & d_1     \\[0.3em]
     0       & 1       & 0       &\cdots& 0       & d_2     \\[0.3em]
     0       & 0       & 1       &\cdots& 0       & d_3     \\[0.3em]
     \vdots  & \vdots  & \vdots &\ddots& \vdots             \\[0.3em]
     0       & 0       & 0      &\cdots& 1        & d_n
     \end{bmatrix}
  (\#eq:gaussjordan)
\end{equation}


Sehingga penyelesaian persamaan linier tersebut adalah nilai $d_1,d_2,d3,\dots,d_n$ dan atau:

\begin{equation}
\begin{matrix}
  x_1=d_1 \\
  x_2=d_2 \\
  x_3=d_3 \\
  \cdots\cdots\cdots\cdots\cdots\cdots\cdots\cdots       \\
  x_n=d_n
   \end{matrix}
  (\#eq:gaussjordansolution)
\end{equation}

```{example, gaussjordanexm}
Selesaikan sistem persamaan berikut:
```

$$
\begin{matrix}
  x_1+x_2=3 \\
  2x_1+4x_2=8 \\
\end{matrix}
$$

**Jawab**:

*Augmented matrix* dari persamaan linier tersebut adalah sebagai berikut:

$$
\begin{bmatrix}
     1 & 1 & 3     \\[0.3em]
     2 & 4 & 8
\end{bmatrix}
$$

Operasi baris elementer selanjutnya dilakukan pada matriks tersebut. 

\begin{equation*}
\begin{bmatrix}
     1 & 1 & 3     \\[0.3em]
     2 & 4 & 8
\end{bmatrix}
\begin{matrix}
  B_2-2B_1 \\
  \implies 
\end{matrix}
\begin{bmatrix}
     1 & 1 & 3     \\[0.3em]
     0 & 2 & 2
\end{bmatrix}
\end{equation*}

\begin{equation*}
\begin{bmatrix}
     1 & 1 & 3     \\[0.3em]
     0 & 2 & 2
\end{bmatrix}
\begin{matrix}
  \frac{B_2}{2} \\
  \implies
\end{matrix}
\begin{bmatrix}
     1 & 1 & 3     \\[0.3em]
     0 & 1 & 1
\end{bmatrix}
\end{equation*}

\begin{equation*}
\begin{bmatrix}
     1 & 1 & 3     \\[0.3em]
     0 & 1 & 1
\end{bmatrix}
\begin{matrix}
  B_1-B_2 \\
  \implies
\end{matrix}
\begin{bmatrix}
     1 & 0 & 2     \\[0.3em]
     0 & 1 & 1
\end{bmatrix}
\end{equation*}

Penyelesaian persamaan linier tersebut adalah sebagai berikut:

$$
x_1=2\ dan\ x_2=1
$$

-------------

**Algoritma Metode Eliminasi Gauss-Jordan**

1. Masukkan matriks $A$ dan vektor $B$ beserta ukurannya $n$
2. Buat *augmented matrix* $\left[A|B\right]$ namakan dengan $A$
3. Untuk baris ke-$i$ dimana $i=1$ s/d $n$

  * Perhatikan apakah nilai $a_{i.i}$ sama dengan nol:
  
    + **Bila ya**: pertukakan baris ke-$i$ dan baris ke-$i+k\le n$, dimana $a_{i+k.i}$ tidak sama dengan nol, bila tidak ada berarti perhitungan tidak bisa dilanjutkan dan proses dihentikan dengan tanpa penyelesaian.
    + **Bila tidak**: lanjutkan

  * Jadikan nilai diagonalnya menjadi satu dengan cara untuk setiap kolom $k$ dimana $k=1$ s/d $n+1$, hitung $a_{i.k}=\frac{a_{i.k}}{a_{i.i}}$

4. Untuk baris ke-$j$, dimana $j=i+1$ s/d $n$. Lakukan operasi baris elementer untuk kolom $k$ dimana $k=1$ s/d $n$.

  * Hitung $c=a_{j.i}$
  * Hitung $a_{j.k}=a_{j.k}-c.a_{i.k}$

5. Penyelesaian untuk $i=n$ s/d 1 disajikan pada Persamaan \@ref(eq:gaussjordansolution).

----------------

Dari algoritma tersebut, kita dapat membangun sebuah fungsi menggunakan `R`. Fungsi tersebut adalah sebagai berikut:

```{r}
gauss_jordan <- function (a){
    m <- nrow (a)
    n <- ncol (a)
    piv <- 1
    
# cek elemen diagonal utama apakah bernilai nol
    for(row_curr in 1:m){
        if(piv <= n){
            i <- row_curr
            while(a[i, piv] == 0 && i < m){
                i <- i + 1
                if(i > m){
                    i <- row_curr
                    piv <- piv + 1
                    if(piv > n)
                        return (a)
                }
            }

# jika diagonal utama bernilai nol,lakukan row swapping
            if(i != row_curr)
                a <- swap_row(a, i, row_curr)
            
# proses pembentukan matriks reduced row echelon form
            piv_val <- a[row_curr , piv]
            a <- scale_row (a, row_curr , 1 / piv_val)
            for(j in 1: m){
                if(j != row_curr){
                    k <- a[j, piv]/a[row_curr, piv]
                    a <- replace_row (a, row_curr, j, -k)
                }
            }
            piv <- piv + 1
        }
    }
    return (a)
}
```

Dengan menggunakan fungsi `gauss_jordan()`, sistem persamaan linier pada Contoh \@ref(exm:gaussjordanexm):

```{r}
(m <- matrix(c(1,2,1,4,3,8), nrow=2))
gauss_jordan(m)
```

```{example, gaussjordanexm2}
Dengan menggunakan fungsi `gauss_jordan()`, carilah penyelesaian sistem persamaan linier pada Contoh \@ref(exm:refexm) dan Contoh \@ref(exm:refexm2):
```

**Jawab**:

Untuk Contoh \@ref(exm:refexm):

```{r}
am <- c(1,1,2,
        1,2,1,
        1,-1,2,
        6,2,10)
m <- matrix(am, nrow=3)

gauss_jordan(m)
```

Untuk Contoh \@ref(exm:refexm2):

```{r}
m <- matrix(c(2,3,1,1,2,-5,
              -1,-2,4,1,1,3), 
            nrow=3)
gauss_jordan(m)
```
  
### Matrik Tridiagonal {#matriktridiagonal}

Metode eliminasi Gauss merupakan metode yang sederhana untuk digunakan khususnya jika semua koefisien bukan nol berkumpul pada diagonal utama dan beberapa diagonal sekitarnya. Suatu sistem yang bersifat demikian disebut sebagai *banded* dan banyaknya diagonal yang memuat koefisien bukan nol disebut sebagai *bandwidth*. Contoh khusus yang sering dijumpai adalah matriks tridiagonal yang memiliki *bandwidth* tiga.

Proses eliminasi untuk matriks tridiagonal bersifat trivial karena dengan membentuk sebuah subdiagonal tambahan, proses substitusi mundur segera dapat dilakukan. Bentuk matriks tridiagonal disajikan pada Persamaan \@ref(eq:matrikstridiagonal).

\begin{equation}
\begin{bmatrix}
     a_{1,1} & a_{1,2} & 0       &\cdots& 0                 \\[0.3em]
     a_{2,1} & a_{2,2} & a_{2,3} &\cdots& 0             \\[0.3em]
     0       & a_{3,2} & a_{3,3} &\cdots& 0             \\[0.3em]
     \vdots  & \vdots  & \vdots  &\ddots& \vdots            \\[0.3em]
     0       & 0       & 0       &\cdots& a_{m,n}
     \end{bmatrix}
\begin{bmatrix}
     x_1                                          \\[0.3em]
     x_2                                          \\[0.3em]
     x_3                                          \\[0.3em]
     \cdots                                       \\[0.3em]
     x_n                                       
     \end{bmatrix}
= \begin{bmatrix}
     b_1                                          \\[0.3em]
     b_2                                          \\[0.3em]
     b_3                                          \\[0.3em]
     \cdots                                       \\[0.3em]
     b_n                                       
     \end{bmatrix}
  (\#eq:matrikstridiagonal)
\end{equation}

Penyelesaian persamaan tersebut disajikan pada Persamaan \@ref(eq:solusimatrikstridiagonal).

\begin{equation}
x_n=\frac{b_n}{a_{m.n}};\ x_i=\frac{b_i-a_{i,j+1}x_{i+1}}{a_{i,j}}
  (\#eq:solusimatrikstridiagonal)
\end{equation}

dimana $i=n-1,n-2,\dots,1$.

Pada beberapa *textbook*, diagonal matriks sering dilambangkan dengan $l$(diagonal bawah), $d$(diagonal tengah), dan $u$ (diagonal atas). Bentuk matriksnya disajikan pada Persamaan \@ref(eq:matrikstridiagonal2).

\begin{equation}
\begin{bmatrix}
     d_{1} & u_{2} & 0       &\cdots& 0                 \\[0.3em]
     l_{2} & d_{2} & u_{3} &\cdots& 0             \\[0.3em]
     0       & l_{3} & d_{3} &\cdots& 0             \\[0.3em]
     \vdots  & \vdots  & \vdots  &\ddots& \vdots            \\[0.3em]
     0       & 0       & 0       &\cdots& d_{n}
     \end{bmatrix}
\begin{bmatrix}
     x_1                                          \\[0.3em]
     x_2                                          \\[0.3em]
     x_3                                          \\[0.3em]
     \cdots                                       \\[0.3em]
     x_n                                       
     \end{bmatrix}
= \begin{bmatrix}
     b_1                                          \\[0.3em]
     b_2                                          \\[0.3em]
     b_3                                          \\[0.3em]
     \cdots                                       \\[0.3em]
     b_n                                       
     \end{bmatrix}
  (\#eq:matrikstridiagonal2)
\end{equation}

-------------

**Algoritma Penyelesaian Matrik Tridiagonal**

1. Bentuk sistem persamaan linier menjadi matriks pada Persamaan \@ref(eq:matrikstridiagonal2).
2. Lakukan *foward sweep*. Setiap elemen diagonal $l$ dieliminasi menggunakan reduksi baris.

* Untuk $i=1$

  + Hitung $u_1=\frac{u_1}{d_1}$
  + Hitung $b_1=\frac{b_1}{d_1}$

* Untuk $i=2$ s/d $n-1$

  + Hitung $u_i=\frac{u_i}{d_i-l_i\times u_{i-1}}$
  + Hitung $b_i=\frac{b_i-l_i\times u_{i-1}}{d_i-l_i\times u_{i-1}}$

* Hitung $b_n=\frac{b_n-l_n\times u_{n-1}}{d_n-l_n\times u_{n-1}}$

3. Lakukan *backward sweep*. Setiap elemen diagonal $u$ dilakukan eliminasi.

* Untuk $i=n-1$ s/d $1$

  + Hitung $x_n=b_i-u_i\times x_{i+1}$

* Hitung $x_n=b_n$

----------------------

Berdasarkan algoritma tersebut, kita dapat membangun sebuah fungsi pada `R`. Fungsi penyelesaian matriks tridiagonal disajikan sebagai berikut:

```{r}
tridiagmatrix <- function (L, D, U, b){
  n <- length (D)
  L <- c(NA , L)
  
  ## forward sweep
  U[1] <- U[1] / D[1]
  b[1] <- b[1] / D[1]
  for(i in 2:(n - 1)){
      U[i] <- U[i] / (D[i] - L[i] * U[i - 1])
      b[i] <- (b[i] - L[i] * b[i - 1]) /
      (D[i] - L[i] * U[i - 1])
  }
  b[n] <- (b[n] - L[n] * b[n - 1])/(D[n] - L[n] * U[n - 1])
  
  ## backward sweep
  x <- rep.int (0, n)
  x[n] <- b[n]
  for(i in (n - 1) :1)
      x[i] <- b[i] - U[i] * x[i + 1]
  return (x)
}
```

```{example, tridiagexm}
Selesaikan sistem persamaan berikut menggunakan fungsi `tridiagmatrix()` dan fungsi `gauss_jordan()`!
```

$$
\begin{matrix}
  3x_1+4x_2=20 \\
  4x_1+5x_2-2x_3=28 \\
  2x_2+5x_3-3x_4=18 \\
  3x_3+5x_4=18
\end{matrix}
$$

**Jawab**:

Langkah pertama untuk menyelesaikannya, kita harus merubah persamaan tersebut kedalam bentuk matriks

\begin{equation*}
\begin{bmatrix}
     3 & 4 & 0  & 0     \\[0.3em]
     4 & 5 & 2 & 0     \\[0.3em]
     0 & 2 & 5 & 3     \\[0.3em]
     0 & 0 & 3 & 5
\end{bmatrix}
x = \begin{bmatrix}
     20     \\[0.3em]
     28     \\[0.3em]
     18     \\[0.3em]
     18
\end{bmatrix}
\end{equation*}

Untuk menyelesaikan persamaan tersebut menggunakan fungsi `tridiagmatrix()`, kita perlu membentuk vektor diagonal $l$, $d$, $u$, dan $b$.

```{r}
l <- u <- c(4, 2, 3); d <- c(3, 5, 5, 5)
b <- c(20, 28, 18, 18)
```

Setelah terbentuk, vektor tersebut dapat langsung dimasukkan ke dalam fungsi `tridiagmatrix()`.

```{r}
tridiagmatrix(L=l, D=d, U=u, b=b)
```

Untuk menyelesaikannya menggunakan fungsi `gauss_jordan()`, kita perlu membentuk *augmented matrix*-nya terlebih dahulu.

```{r}
m <- matrix(c(3,4,0,0,4,5,2,0,
              0,2,5,3,0,0,3,5,
              20,28,18,18), nrow=4)
gauss_jordan(m)
```

### Penyelesaian Sistem Persamaan Linier Menggunakan Fungsi `solve()` {#solvefunc}

`R` menyediakan fungsi bawaan `solve()` untuk menyelesaiakan sistem persamaan linier. Format fungsi `solve()` adalah sebagai berikut:

```{r, eval=FALSE}
solve(a,b)
```

> **Catatan**:
>
> - **a**: matriks koefisien atau matriks segiempat
> - **b**: vektor konstanta

Berikut adalah contoh penerapan fungsi `solve()` pada sistem persamaan linier yang disajikan pada Contoh \@ref(exm:refexm2):

```{r}
# memecah matriks m menjadi matriks koefisien dan vektor konstanta
a <- matrix(c(2,3,1,1,2,-5,-1,-2,4),nrow=3)
b <- c(1,1,3)

solve(a,b)
```

Jika kita hanya memasukkan matriks persegi, maka output yang akan dihasilkan adalah invers dari matriks yang kita masukkan.

```{r}
solve(a)
```

Jika kita mengalikan invers dengan matriks semula, maka akan dihasilkan output berupa matriks identitas.

```{r}
a%*%solve(a)
```

### Penyelesaian Sistem Persamaan Linier Menggunakan Fungsi 'Solve.tridiag()` {#solvetridiagfunct}

Penyelesaian matriks tridiagonal selain menggunakan fungsi `solve()`, juga dapat menggunakan fungsi `Solve.tridiag()` dari Paket `limSolve`. Untuk menginstall dan mengaktifkan Paket tersebut, jalankan sintaks berikut:

```{r, eval=FALSE}
install.packages("limSolve")
```

```{r, message=FALSE, warning=FALSE}
library(limSolve)
```

Fungsi `Solve.tridiag()` memiliki format sebagai berikut:

```{r, eval=FALSE}
Solve.tridiag ( diam1, dia, diap1, B=rep(0,times=length(dia)))
```

> **Catatan**:
>
> - **diam1**: vektor bukan nol di bawah diagonal matriks
> - **dia**: vektor bukan nol pada diagonal matriks
> - **diap1**: vektor bukan nol di atas diagonal matriks
> - **B**: vektor konstanta

Untuk memahami penerapannya, kita akan menggunakan kembali matriks yang ada pada Contoh \@ref(exm:tridiagexm).

```{r}
l <- u <- c(4, 2, 3); d <- c(3, 5, 5, 5)
b <- c(20, 28, 18, 18)
Solve.tridiag(diam1=l, dia=d, diap1=u, B=b)
```

## Dekomposisi Matriks {#dekomposisimatriks}

Seringkali kita diminta untuk memperoleh nilai penyelesaian suatu persamaan linier $Ax=B$, dimana nilai vektor $B$  yang selalu berubah-ubah. Penggunaan metode eliminasi Gauss mengharuskan untuk menyelesaikan sistem persamaan linier $Ax=B$ secara terpisah untuk setiap perubahan vektor $B$. Untuk menghindari pekerjaan eliminasi yang selalu berulang-ulang, faktorisasi menjadi suatu hal yang dapat dilakukan untuk mempersingkat prosesnya. Faktorisasi atau dekomposisi matriks merupakan suatu algoritma untuk memecah matriks $A$, hasil pemecahan ini selanjutnya digunakan untuk memperoleh penyelesaian sistem persamaan linier melalui perkalian antara vektor $B$ dan hasil faktorisasi matriks $A$. 


### Dekomposisi LU {#ludecomp}

Misalkan kita memiliki persamaan linier seperti yang ditunjukkan oleh Persamaan \@ref(eq:matrikpl2). Pada metode dekomposisi LU, matriks $A$ difaktorkan menjadi matriks $L$ dan matriks $U$, dimana ukuran kedua matriks tersebut harus sama dengan ukuran matriks $A$ atau dapat kita tuliskan bahwa hasil perkalian kedua matriks tersebut akan menghasilkan matriks $A$.

\begin{equation}
A=LU
 (\#eq:LUdecomp)
\end{equation}

Sehingga Persamaan \@ref(eq:matrikpl2) akan menjadi Persamaan \@ref(eq:LUdecomp2).

\begin{equation}
LUx=b
 (\#eq:LUdecomp2)
\end{equation}

Langkah penyelesaian sistem persamaan linier, diawali dengan menghadirkan vektor $t$ yang ditunjukkan pada Persamaan \@ref(eq:LUdecomp3).

\begin{equation}
Ux=t
 (\#eq:LUdecomp3)
\end{equation}

Langkah pada Persamaan \@ref(eq:LUdecomp3) tidak dimaksudkan untuk menghitung vektor $t$, melainkan untuk menghitung vektor $x$. Vektor $t$ diperoleh dengan menggunakan Persamaan \@ref(eq:LUdecomp4).

\begin{equation}
Lx=t
 (\#eq:LUdecomp4)
\end{equation}

Kita dapat menyelesaikan sistem persamaan yang ditunjukkan pada Persamaan \@ref(eq:LUdecomp3) dan Persamaan \@ref(eq:LUdecomp4) menggunakan berbagai algoritma penyelesaian yang telah dibahas sebelumnya. Namun, karena matriks $L$ merupakan matriks segitiga bawah dengan nilai nol berada pada bagian atas diagonal utama, penyelesaian $t$ mengambil langkah yang lebih sedikit. Kondisi ini sama dengan kondisi penyelesaian matriks tridiagonal, dimana kita memanfaatkan sejumlah jalan pintas penyelesaiaannya guna mempercepat komputasi. Matriks segitia bawah $L$ akan berupa matriks persegi dengan ukuran $m$, di mana $m$ merupakan jumlah baris matriks $A$. Persamaan \@ref(eq:LUdecomp4) dalam bentuk matriks akan terlihat seperti Persamaan \@ref(eq:LUdecomp5).

\begin{equation}
Lt=
\begin{bmatrix}
     1       & 0       & 0 &\cdots& 0           \\[0.3em]
     l_{2,1} & 1       & 0 &\cdots& 0           \\[0.3em]
     l_{3,1} & l_{3,2} & 1 &\cdots& 0           \\[0.3em]
     \vdots  & \vdots  & \vdots  &\ddots& \vdots            \\[0.3em]
     l_{m,1} & l_{m,2} & l_{m,3} &\cdots& 1
     \end{bmatrix}
\begin{bmatrix}
     t_1                                          \\[0.3em]
     t_2                                          \\[0.3em]
     t_3                                          \\[0.3em]
     \cdots                                       \\[0.3em]
     t_n                                       
     \end{bmatrix}
= \begin{bmatrix}
     b_1                                          \\[0.3em]
     b_2                                          \\[0.3em]
     b_3                                          \\[0.3em]
     \cdots                                       \\[0.3em]
     b_n                                       
     \end{bmatrix}
  (\#eq:LUdecomp5)
\end{equation}

Berdasarkan Persamaan \@ref(eq:LUdecomp5), diketahui nilai $t_1=b_1$. Nilai ini selanjutnya dapat digunakan untuk melakukan proses substitusi guna memperoleh seluruh nilai vektor $t$. Proses ini disebut sebagai *foward substitution*. Proses substitusi dapat dituliskan menggunakan Persamaan \@ref(eq:LUdecomp6).

\begin{equation}
t_i=b_i-\sum_{j=1}^{i-1}l_{i,j}t_i
  (\#eq:LUdecomp6)
\end{equation}

Seteleh nilai vektor $t$ dihitung, kita dapat menghitung nilai $x$ pada Persamaan \@ref(eq:LUdecomp7).

\begin{equation}
Ux=
\begin{bmatrix}
     u_{1,1} & u_{1,2} & u_{1,3} &\cdots& u_{1,n}           \\[0.3em]
     0       & u_{2,2} & u_{2,3} &\cdots& u_{2,n}           \\[0.3em]
     0       & 0       & u_{3,3} &\cdots& u_{3,n}           \\[0.3em]
     \vdots  & \vdots  & \vdots  &\ddots& \vdots            \\[0.3em]
     0       & 0      & 0        &\cdots& u_{m,n}
     \end{bmatrix}
\begin{bmatrix}
     x_1                                          \\[0.3em]
     x_2                                          \\[0.3em]
     x_3                                          \\[0.3em]
     \cdots                                       \\[0.3em]
     x_n                                       
     \end{bmatrix}
= \begin{bmatrix}
     t_1                                          \\[0.3em]
     t_2                                          \\[0.3em]
     t_3                                          \\[0.3em]
     \cdots                                       \\[0.3em]
     t_n                                       
     \end{bmatrix}
  (\#eq:LUdecomp7)
\end{equation}

Jika diperhatikan, kita dapat mengetahui mengetahui nilai $x_n=\frac{t_n}{u_{m,n}}$. Nilai tersebut selanjutnya dapat digunakan untuk melakukan proses susbtitusi pada nilai lainnya. Proses substitusi ini disebut sebagai *backward substitution*. Proses dekomposisi atau faktorisasi LU digambarkan pada Gambar \@ref(fig:LUfig).

```{r LUfig,echo=FALSE, fig.cap='Tahapan dekomposisi LU.', tidy=FALSE, out.width='90%', fig.align='center', message=FALSE, warning=FALSE}
library(knitr)
img1_path <- "./images/LU.png"
include_graphics(img1_path)

```

Dekomposisi LU didasarkan pada operasi baris elementer. Pertama, kita perlu menemukan matriks segitiga atas yang sesuai dengan matriks $A$. Solusi untuk melakukan dekomposisi bisa jadi tak terhingga, namun solusi yang paling sederhana adalah mengubah matriks $A$ menjadi matriks *row echelon form*. Kedua, $L$ harus menjadi matriks segitiga bawah yang mereduksi ke-$l$ dengan mengikuti operasi baris yang sama yag menghasilkan $U$. Kita dapat menggunakan algoritma Doolittle untuk menghasilkan $L$, di mana nilai setiap entri dalam matriks segitiga bawah merupakan pengali yang digunakan untuk menghilangkan entri yang sesuai untuk setiap proses *row replacement*. 

Pada praktiknya, proses eliminasi Gauss untuk memperoleh matriks $U$ kadang menghasilkan nol di kolom pivotnya. Kondisi tersebut mengharuskan kita untuk melakukan proses *row swapping* atau pertukaran baris (biasanya dengan baris bawahnya) untuk pivot bukan nol. Jika proses tersebut berhasil dilakukan bisa jadi matriks $A$ mungkin setara dengan matriks LU, tetapi tidak sama dalam hal urutan nilai pada tiap barisnya. Agar kita dapat memperoleh hasil yang sama (matriks A sama dengan matriks LU), diperlukan matriks ketiga, $P$. Matriks ini merupakan matriks identitas dengan ukuran sama dengan matriks $A$. Jika pertukaran baris dilakukan selama proses pembentukan matriks $U$, maka pertukaran baris yang sama juga akan diimplemenntasikan pada matriks $P$. oleh karena itu, dalam praktiknya matriks $A=PLU$ dan perkalian dengan matriks $P$ berfungsi untuk mengembalikan urutan baris.

```{example, LUexmp}
Selesaikan sistem persamaan linier berikut menggunakan faktorisasi LU
```

$$
\begin{matrix}
  x_1+x_2+3x_4=4 \\
  2x_1+x_2-x_3+x_4=1 \\
  3x_1-x_2-x_3+2x_4=-3 \\
  -x_1-2x_2+3x_3-x_4=4
\end{matrix}
$$

**Jawab**:

Nayatakan sistem persamaan tersebut ke dalam bentuk matriks $Ax=b$.

\begin{equation*}
Ux=
\begin{bmatrix}
     1       & 1       & 0       & 3           \\[0.3em]
     2       & 1       & -1      & 1           \\[0.3em]
     3       & -1      & -1      & 2           \\[0.3em]
     -1      & 2       & 3       & -1           
     \end{bmatrix}
\begin{bmatrix}
     x_1                                          \\[0.3em]
     x_2                                          \\[0.3em]
     x_3                                          \\[0.3em]
     x_4                                       
     \end{bmatrix}
= \begin{bmatrix}
     4                                          \\[0.3em]
     1                                          \\[0.3em]
     -3                                          \\[0.3em]
     4                                       
     \end{bmatrix}
\end{equation*}

Lakukan operasi baris elementer pada matriks $A$ untuk memperoleh matriks $U$. Urutan operasi baris elementer yang dilakukan adalah sebagai berikut: 

* $\left(B_2-2B_1\right)\to B_2 \to l_{2,1}=2$, 
* $\left(B_3-3B_1\right)\to B_3 \to l_{3,1}=3$, 
* $\left(B_4+B_1\right)\to B_4 \to l_{4,1}=-1$, 
* $\left(B_3-4B_2\right)\to B_3\to l_{3,2}=4$, 
* $\left(B_4+3B_2\right)\to B_4 \to l_{4,2}=-3$,
* $l_{4,3}=0$

Simpan pengali tiap tahapan pada masing-masing elemen matriks $L$. Hasil operasi tersebut akan menghasilkan matriks triangular $U$.

$$
U=
\begin{bmatrix}
     1       & 1       & 0       & 3           \\[0.3em]
     0       & -1      & -1      & -5          \\[0.3em]
     0       & 0       & 3       & 13          \\[0.3em]
     0       & 0       & 0       & -13           
\end{bmatrix}
$$

Untuk matriks $L$ sebagai berikut:

$$
L=
\begin{bmatrix}
     1         & 0       & 0       & 0           \\[0.3em]
     2         & 1       & 0       & 0           \\[0.3em]
     3         & 4       & 1       & 0           \\[0.3em]
     -1        & -3      & 0       & 1           
\end{bmatrix}
$$

Karena pada proses operasi baris elementer tidak terdapat operasi pertukaran baris, maka matriks $P$ tidak mengalami perubahan:

$$
P=
\begin{bmatrix}
     1         & 0       & 0       & 0           \\[0.3em]
     0         & 1       & 0       & 0           \\[0.3em]
     0         & 0       & 1       & 0           \\[0.3em]
     0         & 0       & 0       & 1           
     \end{bmatrix}
$$

Lakukan operasi *forward substitution* menggunakan Persamaan \@ref(eq:LUdecomp5).

\begin{equation*}
\begin{bmatrix}
      1         & 0       & 0       & 0           \\[0.3em]
      2         & 1       & 0       & 0           \\[0.3em]
      3         & 4       & 1       & 0           \\[0.3em]
      -1        & -3      & 0       & 1
     \end{bmatrix}
\begin{bmatrix}
     t_1                                          \\[0.3em]
     t_2                                          \\[0.3em]
     t_3                                          \\[0.3em]
     t_4                                       
     \end{bmatrix}
= \begin{bmatrix}
     4                                          \\[0.3em]
     1                                          \\[0.3em]
     -3                                          \\[0.3em]
     4                                       
     \end{bmatrix}
\end{equation*}

Berdasarkan hasil perhitungan diperoleh nilai vektor $t$.

$$
t_1=4, t_2=1, t_3=-3, t_4=4
$$

Operasi terakhir yang perlu dilakukan untuk memperoleh nilai $x$ adalah dengan melakukan *backward substitution* menggunakan nilai vektor $t$ yang telah dihitung.

\begin{equation*}
\begin{bmatrix}
     1       & 1       & 0       & 3           \\[0.3em]
     0       & -1      & -1      & -5          \\[0.3em]
     0       & 0       & 3       & 13          \\[0.3em]
     0       & 0       & 0       & -13
     \end{bmatrix}
\begin{bmatrix}
     x_1                                          \\[0.3em]
     x_2                                          \\[0.3em]
     x_3                                          \\[0.3em]
     x_4                                       
     \end{bmatrix}
= \begin{bmatrix}
     4                                          \\[0.3em]
     7                                          \\[0.3em]
     13                                          \\[0.3em]
     -13                      
     \end{bmatrix}
\end{equation*}

Berdasarkan hasil perhitungan diperoleh nilai $x$ sebagai berikut:

$$
x_1=-1, x_2=2, x_3=0, x_4=1
$$

-------------------

**Algoritma Dekomposisi LU**

1. Masukkan matriks $A$, dan vektor $B$ beserta ukurannya $n$
3. Lakukan langkah poin ke-4 s/d poin 5 untuk meperoleh matriks $U$.
4. Untuk baris ke-$i$ di mana $i=1$ s/d $n$, perhatikan apakah nilai $a_{i,j}$ sama dengan nol. 

* **Bila iya**, lakukan *row swapping* antara baris ke-$i$ dan baris ke-$i+k\leq n$, dimana $a_{i+k,j}$ tidak sama dengan nol. Bila tidak ada berarti perhitungan tidak bisa dilanjutkan dan proses dihentikan dengan tanpa penyelesaian.
* **Bila tidak**, lanjutkan.

5. Untuk baris ke-$j$, dimana $j=i+1$ s/d $n$, lakukan operasi baris elementer:

* Hitung $c=\frac{a_{j,i}}{a_{i,i}}$
* untuk kolom $k$, dimana $k=1$ s/d $n+1$, hitung $a_{j,k}=a_{j,k}-c_i.a_{i,k}$

6. Lakukan langkah poin ke-7 s/d poin 9 untuk memperoleh matriks $L$
7. Untuk diagonal matriks $L$ isikan dengan nilai 1 dan elemen di atas diagonal dengan nilai nol.
8. Untuk elemen di bawah diagonal isikan dengan faktor pengali operasi baris elementer matriks $U$.
9. Lakukan proses *forward substitution* menggunakan Persamaan \@ref(eq:LUdecomp6) untuk memperoleh nilai vektor $t$.
10. Lakukan *backward substituion* menggunakan Persamaan \@ref(eq:refsolution).

----------------------------

Berdasarkan algoritma tersebut, kita dapat menyusun algoritma faktorisasi LU menggunakan `R`. Berikut adalah sintaks yang digunakan:

```{r}
lu_solve <- function(a, b=NULL){
    m <- nrow(a)
    n <- ncol(a)
    piv <- 1

# membentuk matriks identitas P dan L
    P <- L <- diag(n)

# cek elemen diagonal utama apakah bernilai nol
    for(row_curr in 1:m){
        if(piv <= n){
            i <- row_curr
            while(a[i, piv] == 0 && i < m){
                i <- i + 1
                if(i > m){
                    i <- row_curr
                    piv <- piv + 1
                    if(piv > n)
                        return(list(P = P, L = L, U = a))
                }
            }
            
# jika elemen diagonal utama bernilai nol,lakukan row swapping
            if(i != row_curr){
                a <- swap_row(a, i, row_curr)
                P <- swap_row(P, i, row_curr)
            }
            
  # pembentukan matriks L dan U
            for(j in row_curr:m)
                if(j != row_curr){
                    k <- a[j, piv]/a[row_curr, piv]
                    
  # matriks U
                    a <- replace_row(a, row_curr, j, -k)
                    
  # pengisian elemen matriks L
                    L[j, piv] <- k
                }
            piv <- piv + 1
        }
    }
    
# penyelesaian persamaan linier
    if(is.null(b)){
      return(list(P = P, L = L, U = a))
    }else{
      
      # forward substitution
      t <- forwardsolve(L, b)
      
      # backward substitution
      x <- backsolve(a, t)
      return(list(P = P, L = L, U = a, result=x))
     }
}
```

Kita dapat menyelesaikan sistem persamaan linier pada Contoh \@ref(exm:LUexmp) menggunakan fungsi yang telah kita buat.

```{r}
# membuat matriks a dan vektor b
a <- matrix(c(1,2,3,-1,1,1,-1,2,
              0,-1,-1,3,3,1,2,-1),
            nrow=4)
b <- c(4,1,-3,4)

# penyelesaian
decomp<-lu_solve(a,b)
```

Untuk membentuk kembali matriks $A$, kita dapat mengalikan matriks $L$, $U$, dan $P$.

```{r}
decomp$L%*%decomp$U%*%decomp$P
```

```{example, LUexmp2}
Lakukan dekomposisi LU pada matriks berikut dan lakukan pengecekan apakah perkalian hasil dekomposisi matriks akan menghasilkan matriks semula! 
```

$$
\begin{bmatrix}
     0         & 1       & -1                  \\[0.3em]
     1         & 5       & 9                   \\[0.3em]
     7         & -1      & -5                  
\end{bmatrix}
$$

**Jawab**:

Lakukan proses dekomposisi menggunakan fungsi `lu_solve()`.

```{r}
# membentuk matriks a
(A <- matrix(c(0, 1, 7, 1, 5, -1, -2, 9, -5), 3))

# dekomposisi lu
decomp<-lu_solve(A)
```

Lakukan pengecekan apakah matriks hasil dekomposisi akan menghasilkan matriks $A$.

```{r}
decomp$P %*% decomp$L %*% decomp$U
```

Fungsi `lu()` pada Paket `Matrix` dapat digunakan untuk melakukan dekomposisi LU. Untuk meggunakan fungsi tersebut, kita harus menginstall dan mengaktifkan Paket `Matrix`.

```{r, eval=FALSE}
install.packages("Matrix")
```

```{r, warning=FALSE, message=FALSE}
library(Matrix)
```

Untuk dapat menggunakannya kita hanya perlu menginputkan matriks kedalam fungsi tersebut. Berikut adalah contoh penerapannya:

```{r}
# membuat matriks a 
a <- Matrix::Matrix(round(rnorm(9),2), nrow=3)

# dekomposisi
lum <- Matrix::lu(a)
lum
```

Untuk menampilkan hasil dekomposisi, jalankan fungsi `expand()`.

```{r}
decomp <- Matrix::expand(lum)
decomp
```

### Dekomposisi Cholesky

Dekomposisi Cholesky  memberikan faktorisasi matriks alternatif sehingga $A = LL^T$, di mana $L^T$ merupakan transpose konjugat dari matriks $L$. Dalam kasus ini, penulis hanya bekerja dengan matriks rill dengan nilai rill dan bagian imajiner nol. Jadi untuk tujuan *sub-chapter* ini, matriks $L^T$ hanyalah transpose dari matriks $L$.

Seperti dekomposisi LU, dekomposisi Cholesky dapat digunakan untuk menyelesaikan sistem persamaan linier. Kelebihannya, Menemukan dekomposisi Cholesky jauh lebih cepat daripada dekomposisi LU. Namun, dekomposisi ini hanya terbatas pada matriks tertentu saja. Dekomposisi Cholesky hanya dapat digunakan pada matriks definit positif dan simetris. Matriks simeteris merupakan matriks yang nilai di atas dan di bawah diagonalnya simetris atau sama; secara matematis, untuk semua $i$ dan $j$ pada matriks $A$, $a_{i;j}=a_{j;i}$. Definit positif berarti bahwa setiap entri pivot (nilai elemen diagonal utama) selelu bernilai positif. Selain itu, untuk matriks definit positif, hubungan $xAx>0$ untuk semua vektor, $x$.

Karena $L^∗$ transpose dari matriks $L$, maka $l^{T}_{i,j} = l_{j,i}$ untuk semua nilai $i$ dan $j$. Tanpa kendala (*constraint*) ini, dekomposisi Cholesky akan mirip dekomposisi LU. Tetapi dengan kendala ini, nilai elemen matriks $L$ dan $L^T$ harus dipilih dengan cermat sehingga hubungan $A = LL^T$ berlaku. Bentuk dekomposisi Cholesky disajikan pada Persamaan \@ref(eq:cholesky).

\begin{equation}
\begin{bmatrix}
     a_{1,1} & a_{1,2} & a_{1,3} &\cdots& a_{1,m}           \\[0.3em]
     a_{2,1} & a_{2,2} & a_{2,3} &\cdots& a_{2,m}           \\[0.3em]
     a_{3,1} & a_{3,2} & a_{3,3} &\cdots& a_{3,m}           \\[0.3em]
     \vdots  & \vdots  & \vdots  &\ddots& \vdots            \\[0.3em]
     a_{m,1} & a_{m,2} & a_{m,3} &\cdots& a_{m,m}
     \end{bmatrix}
=
\begin{bmatrix}
     l_{1,1} & 0       & 0       &\cdots& 0           \\[0.3em]
     l_{2,1} & l_{2,2} & 0       &\cdots& 0           \\[0.3em]
     l_{3,1} & l_{3,2} & l_{3,3} &\cdots& 0           \\[0.3em]
     \vdots  & \vdots  & \vdots  &\ddots& \vdots            \\[0.3em]
     l_{m,1} & l_{m,2} & l_{m,3} &\cdots& l_{m,m}
     \end{bmatrix}
\begin{bmatrix}
     l_{1,1} & l_{1,2} & l_{1,3} &\cdots& l_{1,m}           \\[0.3em]
     0       & l_{2,2} & l_{2,3} &\cdots& l_{2,m}           \\[0.3em]
     0       & 0       & l_{3,3} &\cdots& l_{3,m}           \\[0.3em]
     \vdots  & \vdots  & \vdots  &\ddots& \vdots            \\[0.3em]
     0       & 0       & 0       &\cdots& l_{m,m}
     \end{bmatrix}
  (\#eq:cholesky)
\end{equation}

Untuk setiap elemen matriks $A$ memiliki hubungan yang dituliskan pada Persamaan \@ref(eq:cholesky2).

\begin{equation}
a_{i,j}=\sum_{k=1}^mL_{i,k}L_{k,j}
  (\#eq:cholesky2)
\end{equation}

Berdasarkan Persamaan \@ref(eq:cholesky), sejumlah nilai elemen $L_{i,k}$ dan $L_{k,j}$ adalah nol. Nilai tiap elemen diagonal utama yang tidak bernilai nol dihitung menggunakan Persamaan \@ref(eq:cholesky3).

\begin{equation}
l_{i,i}=\sqrt{\left(a_{i,i}-\sum_{k=1}^{i-1}l_{i,k}^2\right)}
  (\#eq:cholesky3)
\end{equation}

Elemen diagonal dihitung menggunakan Persamaan \@ref(eq:cholesky5)

\begin{equation}
l_{i,j}=\frac{1}{l_{i,i}}\left(a_{i,j}-\sum_{k=1}^{i-1}l_{i,k}l_{j,k}\right)
  (\#eq:cholesky5)
\end{equation}

----------------------------

**Algoritma Dekomposisi Cholesky**

1. Masukkan matriks $A$, dan vektor $B$ beserta ukurannya $n$.
2. Untuk elemen matriks $L$, hitung menggunakan Persamaan \@ref(eq:cholesky5).
3. Untuk nilai diagonal utama matriks $L$, hitung menggunakan Persamaan \@ref(eq:cholesky3).
4. Untuk memperoleh matriks $L^T$, lakukan transpose pada matriks $L$.
5. Untuk memperoleh nilai $x$,

* Hitung vektor $t$ menggunakan Persamaan \@ref(eq:LUdecomp4).
* Hitung vektor $x$ menggunakan Persamaan \@ref(eq:LUdecomp3), dimana matriks $U=L^T$.

--------------------------

Berdasarkan algoritma tersebut, kita dapat menyusun fungsi pada `R` untuk melakukan dekomposisi Cholesky. Fungsi tersebut disajikan pada sintaks berikut:

```{r}
cholesky_solve <- function(a, b=NULL){
    m <- nrow(a)
   
# membentuk matriks L dengan elemen nol
    L = diag(0,m)

# Perhitungan elemen matriks L
    for(i in 1:m){
        for(k in 1:i){
            p_sum <- 0
            for(j in 1:k)
                p_sum <- p_sum + L[j,i]*L[j,k]
                
# Pehitungan elemen diagonal utama
            if(i==k)
                L[k,i]<-sqrt(a[i,i]-p_sum)
            else
                L[k,i]<-(a[k,i]-p_sum)/L[k,k]
        }
    }
    
# Perhitungan elemn matriks L*
    tL <- t(L)
    
# penyelesaian persamaan linier
    if(is.null(b)){
      return(list(L = L, tL = tL, a = a))
    }else{
      
      # forward substitution
      t <- forwardsolve(L, b)
      
      # backward substitution
      x <- backsolve(tL, t)
      return(list(L = L, tL = tL, a = a, result=x))
     }
}
```

```{example, cholexm2}
Dengan menggunakan fungsi `cholesky_solve()`, lakukan dekomposisi pada matriks berikut! Lakukan pengecekan pada hasil dekomposisi apakah hasil kali matriks dekomposisi akan menghasilkan matriks semula!
```

$$
\begin{bmatrix}
     9         & -3       & 6                  \\[0.3em]
     -3         & 17       & -10                   \\[0.3em]
     6         & -10      & 12                  
\end{bmatrix}
$$

**Jawab**:

Dekomposisi Cholesky menggunakan fungsi `cholesky_solve()`, disajikan pada sintaks berikut:

```{r}
a <- matrix(c(9,-3,6,-3,17,-10,6,-10,12),3)

# dekomposisi Cholesky
(decomp<-cholesky_solve(a))

# mengecek hasil dekomposisi
decomp$tL %*% decomp$L
```

Fungsi lain yang dapat digunakan untuk melakukan dekomposisi Cholesky adalah menggunakan fungsi `chol()` pada Paket `Matrix`. Pada fungsi tersebut, kita hanya perlu menginputkan objek matrik kedalamnya. Berikut adalah contoh penerapan fungsi tersebut menggunakan matriks pada Contoh \@ref(exm:cholexm2).

```{r}
chol(a)
```

> **Penting!!!**
>
> Fungsi `chol()` hanya menampilkan matriks $L^T$. Untuk menampilkan matriks $L$, kita perlu melakukan transpose

### Dekomposisi Lainnya {#othersdecomp}

Terdapat beberapa algoritma lain yang telah dikembangkan untuk melakukan dekomposisi matriks. Pada buku ini hanya akan dijelaskan secara singkat terkait fungsi yang digunakan dalam melakukan dekomposisi matriks. Algoritma yang akan dijelaskan pada *sub-chapter* ini antara lain: QR, *singular value decomposition* (SVD), dan dekomposisi eigen. Untuk algoritma lainnya, pembaca dapat membaca buku terkait atau mengecek dokumentasinya pada Paket `base`.

#### Dekomposisi QR {#qrdecomp}

Dekomposisi QR merupakan dekomposisi yang penting dalam menyelesaikan sistem persamaan linier. Dekomposisi ini juga berperan penting untuk menghitung koefisien regresi dan pengaplikasian algoritma Newton-Raphson.

Untuk memperoleh informasi terkait dekomposisi ini, pembaca dapat mengetikkan sintaks berikut pada `R`:

```{r, eval=FALSE}
?qr
```

Berikut merupakan contoh penerapan fungsi `qr()` untuk menyelesaikan sistem persamaan linier:

```{r}
# membuat matriks A dan B
set.seed(123)
A <- matrix((1:12)+rnorm(12), nrow=4)
b <- 2:5

# dekomposisi matriks A
qr(A)

# memperoleh penyelesaian SPL
qr.solve(A,b)
```

#### *Singular Value Decomposition* {#svddecomp}

*Singular value decomposition* (SVD) merupakan algoritma faktorisasi matriks yang mendekomposisi matriks segiempat menjadi matriks $UDV_H$, dimana $D$ merupakan mmatriks diagonal non negatif, $U$ dan $V$ merupakan matriks *unitary*, dan $V_H$ merupakan matriks tanspose konjugat dari matriks $V$. Algoritma ini banyak digunakan dalam analisis *principal component*.

Pada `R`, SVD dapat dilakukan menggunakan fungsi `svd()` dari Paket `base`. Berikut adalah sintaks untuk memperoleh informasi terkait fungsi tersebut:

```{r, eval=FALSE}
?svd
```

Berikut adalah contoh penerapan fungsi `svd()`:

```{r}
# dekomposisi matriks A
svd(A)
```

#### Dekomposisi Eigen {#eigendecomp}

Proses umum yang digunakan untuk menemukan nilai eigen  dan vektor eigen suatu matriks segiempat dapat dilihat sebagai proses dari dekomposisi eigen. Proses ini akan mendekomposisi matriks menjadi $VDV^{-1}$, dimana $D$ merupakan matriks diagonal yang terbentuk dari nilai eigen, dan $V$ merupakan vektor eigen. Proses dekomposisi ini akan berguna bagi pembaca yang ingin mempelajari *principal component analysis*.

Fungsi `eigen()` pada Paket `base` dapat digunakan untuk melakukan dekomposisi eigen. Untuk mempelajari lebih jauh terkait fungsi ini, pambaca dapat menjalankan sintaks berikut:

```{r, eval=FALSE}
?eigen
```

Berikut adalah contoh sintaks untuk melakukan dekomposisi eigen:

```{r}
A <- matrix(c(2,-1,0,-1,2,-1,0,-1,2), nrow=3)

# dekomposisi matriks A
eigen(A)
```

## Metode Iterasi {#iteratif}

Pada Chapter \@ref(iteratif) kita akan membahas penyelesaian persamaan linier dengan menggunakan metode iterasi. Terdapat dua metode iterasi yang akan dibahas yaitu iterasi Jacobi dan Gauss-Seidel.

Metode iterasi dimulai dengan estimasi nilai akhir. Setelah menerapkan beberapa perlakuan pada nilai estimasi, hasil perlakuan selanjutnya menjadi nilai estimasi untuk iterasi berikutnya. Proses tersebut akan berlangsung secara terus-menerus hingga ambang batas dipenuhi. Nilai ambang batas dapat berupa jumlah iterasi maksimum atau selisih antara nilai estimasi baru dan estimasi semula lebih kecil dari suatu nilai toleransi yang ditetapkan.

Jumlah kuadrat merupakan metode yang sering digunakan untuk mengecek apakah selisih nilai estimasi baru terhadap estimasi lama lebih kecil dari nilai toleransi yang ditetapkan. Persamaan \@ref(eq:toleransi) menampilkan hubungan antara jumlah kuadrat dan nilai toleransi pada proses iterasi.

\begin{equation}
\sqrt{\sum_{i=1}^n\left(x_i^{n+1}-x_i^{n}\right)^2}<t_0
 (\#eq:toleransi)
\end{equation}

dimana $x^{n}$ merupakan iterasi ke-$n$ dari algoritma dan $t_0$ merupakan nilai toleransi maksimum yang diterima.

### Iterasi Jacobi {#jacobiiter}

Untuk menyelesaikan matriks menggunakan metode iterasi, kita dapat mulai dengan premis terdapat matriks $A$ dan vektor $x$ dan b, sehingga $Ax = b$. Dengan menggunakan metode Jacobi, pertama-tama kita dapat amati bahwa terdapat matriks $R$ dan $D$ yang memiliki hubungan $A = R + D$. Berdasarkan kedua hubungan tersebut, dapat diturunkan operasi matriks melalui persamaan berikut:

\begin{equation}
Ax=b
 (\#eq:jacobi)
\end{equation}

\begin{equation}
Rx+Dx=b
 (\#eq:jacobi2)
\end{equation}

\begin{equation}
Dx=b-Rx
 (\#eq:jacobi3)
\end{equation}

\begin{equation}
x=D^{-1}\left(b-Rx\right)
 (\#eq:jacobi4)
\end{equation}

Persamaan \@ref(eq:jacobi4) merupakan persamaan yang dapat kita gunakan untuk memperoleh nilai $x$. Jika kita menulis kembali persamaan tersebut, maka kita akan memperoleh persamaan yang digunakan sebagai acuan iterasi Jacobi.

\begin{equation}
x^{n+1}=D^{-1}\left(b-Rx^{n}\right)
 (\#eq:jacobi5)
\end{equation}

dimana $D$ merupakan matriks diagonal dengan nilai elemen diagonal berupa diagonal utama matriks $A$. Invers dari matriks $D$ secara sederhana sebagai matriks diagonal sama dengan satu dibagi dengan elemen diagonal utama matriks $A$. Matriks $R$ identik dengan matriks $A$. Namun, diagonal utamanya bernilai nol. Suatu iterasi dikatakan konvergen jika jumlah kuadrat dari vektor $x^{\left(n+1\right)}$ dan vektor $x^{\left(n\right)}$ semakin mengecil.

Suatu persamaan linier yang hendak diselesaikan dengan menggunakan metode iterasi Jacobi harus memenuhi syarat nilai elemen diagonal utama matriks harus lebih dominan. Maksudnya adalah nilai absolut diagonal utama matriks harus lebih besar dari jumlah nilai absolut elemen matriks lainnya pada satu kolom.

```{example, jacobiexm}
Selesaikan sistem persamaan berikut menggunakan iterasi Jacobi!
```

\begin{equation*}
\begin{bmatrix}
     5 & 2 & 3     \\[0.3em]
     2 & 7 & 4     \\[0.3em]
     1 & 3 & 8
\end{bmatrix}
x = \begin{bmatrix}
     40     \\[0.3em]
     39     \\[0.3em]
     55
\end{bmatrix}
\end{equation*}

**Jawab**:

Berdasarkan matriks $A$ (matriks koefisien), kita dapat memastikan bahwa matriks tersebut memiliki nilai dominan pada elemen diagonal utama. Sebagai contoh:

$$
\left|5\right|>\left|2\right|+\left|1\right|\ \ \ \left(kolom\ 1\right)
$$

$$
\left|7\right|>\left|2\right|+\left|3\right|\ \ \ \left(kolom\ 2\right)
$$
Untuk mempermudah proses iterasi, kita akan menggunakan bantuan `R` untuk melakukan komputasi. Langkah pertama yang perlu dilakukan adalah menyiapkan matriks $A$, vektor $b$, dan vektor $x$ (nilai taksiran awal).


```{r}
(A <- matrix(c(5,2,1,2,7,3,3,4,8), 3))
(b <- c(40,39,55))
(x <- rep(0,3))
```

Langkah selanjutnya adalah memperoleh invers matriks $D$.

```{r}
(Dinv <- diag(1/diag(A)))
```

Persiapan terakhir sebelum iterasi dilakukan adalah menyiapkan matriks $R$.

```{r}
(R<-A-diag(diag(A)))
```

Iterasi selanjutnya dilakukan menggunakan Persamaan \@ref(eq:jacobi5).

**iterasi 1**

```{r}
(x1 <- Dinv %*% (b-R%*%x))
```

**iterasi 2**

```{r}
(x2 <- Dinv %*% (b-R%*%x1))
```

**iterasi 3**

```{r}
(x3 <- Dinv %*% (b-R%*%x2))
```

Selama proses iterasi,jumlah akar jumlah kuadrat dihitung. Sebagai contoh berikut disajikan akar jumlah kuadrat pada iterasi ke-3:

```{r}
sqrt(sum(x3-x2)^2)
```

Selama proses iterasi nilai tersebut terus mengecil. Iterasi dihantikan jika nilai akar jumlah kuadrat tersebut lebih kecil dari nilai toleransi. Pada contoh ini digunakan nilai toleransi $10^{-7}$.

Proses iterasi berlangsung sampai dengan iterasi ke-62 dengan nilai $x$ akhir sebagai berikut:

$$
x = \begin{bmatrix}
     4     \\[0.3em]
     1     \\[0.3em]
     6
\end{bmatrix}
$$

--------------------------------------

**Algoritma Iterasi Jacobi**

1. Masukkan matriks $A$, dan vektor $B$ beserta ukurannya $n$.
2. Hitung invers matriks $D$, dimana nilai invernya merupakan matriks diagonal dari satu per diagonal utama matriks $A$.
3. Hitung matriks $R$, dimana $R$ merupakan selisih matriks $A$ dikurangi dengan matriks diagonal dengan entri dari diagonal utama matriks $A$.
4. Tetapkan vektor $x$ estimasi.
5. Tetapkan nilai toleransi maksimum yang dapat diterima.
6. Lakukan iterasi menggunakan Persamaan \@ref(eq:jacobi5).
7. Hitung akar jumlah kuadrat dari vektor $x^{n+1}$ dan vektor $x^n$.
8. Jadikan nilai $x^{n+1}$ sebagai nilai taksiran $x$ untuk iterasi berikutnya.
9. Hentikan proses iterasi jika telah memenuhi syarat yang ditampilkan pada Persamaan \@ref(eq:toleransi).

-------------------------------------

Berdasarkan algoritma tersebut, kita dapat menyusun fungsi sebuah fungsi untuk melakukan iterasi Jacobi. Berikut sintaks yang digunakan:


```{r}
jacobi <- function(a, b, tol=1e-7, maxiter=100){
  n <- length(b)
  iter <- 0
  
  Dinv <- diag(1/diag(a))
  R <- a-diag(diag(a))
  x <- rep(0,n)
  x_new <- rep(tol, n)
  
  while(sqrt(sum(x_new-x)^2)>tol){
            if(iter>maxiter){
              warning("iterasi maksimum tercapai")
              break
            }
            x <- x_new
            x_new <- Dinv %*% (b - R %*% x)
            iter <- iter+1
  }
  return(list(X = x_new, iter=iter))
  
}
```


Berikut adalah penerpan fungsi `jacobi()` tersebut:

```{r}
jacobi(A,b)
```

```{example, jacobiexm2}
Selesaikan sistem persamaan berikut menggunakan fungsi `jacobi()`
```

$$
\begin{bmatrix}
     27 & 6 & -1     \\[0.3em]
     6 & 15 & 2     \\[0.3em]
     1 & 1 & 54
\end{bmatrix}
x = \begin{bmatrix}
     85     \\[0.3em]
     72     \\[0.3em]
     110
\end{bmatrix}
$$

**Jawab**: 

Matriks $A$ (matriks koefisien) berdasarkan sistem persamaan linier tersebut telah memenuhi syarat dari algoritma Jacobi (nilai diagonal utama dominan dibanding nilai lainnya pada satu kolom). Penyelesaian sistem persamaan tersebut, sebagai berikut:

```{r}
A <- matrix(c(27,6,1,6,15,1,-1,2,54), 3)
b <- c(85,72,110)

jacobi(A,b)
```

Nilai vektor $x$ sesungguhnya dapat diperoleh menggunakan fungsi `solve()`.

```{r}
solve(A,b)
```

Berdasarkan hasil perhitungan, vektor $x$ hasil iterasi memiliki nilai identik dengan nilai penyelesaian yang sebenarnya.

Perlu diperhatikan dalam penggunaan fungsi `jacobi()` syarat utama matriks haruslah terpenuhi, seperti: nilai diagonal matriks $A$ lebih besar dari nilai elemen lainnya pada satu kolom. Selain itu, nilai diagonal matriks $D$ tidak boleh sama dengan nol agar inver matriks $D$ dapat diperoleh. Jika syarat-syarat tersebut terpenuhi, maka metode Jacobi dapat diterapkan. Jika tidak terpenuhi, maka penyelesaian yang konvergen mungkin masih dapat diperoleh meskipun penulis tidak dapat menjamin hal tersebut dapat terjadi. 

### Iterasi Gauss-Seidel {#seideliter}

Metode iterasi Gauss-Seidel melakukan dekomposisi pada matriks $A$ menjadi matriks segitiga atas $U$ dan matriks segitiga bawah $L$. Dekomposisi ini tidak sama dengan dekomposisi LU pada Chapter \@ref(ludecomp). Matriks $U$ pada metode Gauss-Seidel merupakan elemen (entri) matriks $A$ pada bagian atas diagonal utama, sedangkan matriks $L$ merupakan elemen diagonal utama dan bagian bawah diagonal utama matriks $A$. Elemen selain yang penulis sebutkan pada kedua matriks tersebut akan bernilai nol. Persamaan iterasi Gauss-Seidel ditampilkan pada Persamaan \@ref(eq:gaussseidel).

\begin{equation}
x^{n+1}=L^{-1}\left(b-Ux^{n}\right)
 (\#eq:gaussseidel)
\end{equation}

Syarat agar suatu sistem persamaan linier dapat diselesaikan menggunakan metode Gauss-Seidel adalah matriks harus memiliki nilai diagonal utama yang dominan. Maksudnya, nilai absolut diagonal utama lebih besar dari jumlah nilai absolut elemen lainnya dalam satu kolom. Jika syarat ini tidak terpenuhi maka metode ini tidak akan memperoleh penyelesaian yang konvergen.


```{example, gaussseidelexm}
Selesaikan sistem persamaan pada Contoh \@ref(exm:jacobiexm2) menggunakan iterasi Gauss-Seidel!
```

**Jawab**:

Kita akan kembali menggunakan bantuan `R` untuk melakukan kalkulasi pada proses iterasi Gauss-Seidel. Kita telah melakukan pengecekan pada sistem persamaan linier pada contoh tersebut dan menghasilkan kesimpulan bahwa persamaan linier tersebut dapat diselesaikan dengan metode Gauss-Seidel. Langkah selanjutnya adalah membentuk matriks $L$ dan $U$.

```{r}
# membentuk matriks U dan L dari matriks A
(L <- U <- A)
```

```{r}
# membentuk matriks L dari entri bagian bawah diagonal utama matriks A
L[upper.tri(A, diag=FALSE)]<-0
L
```

```{r}
# membentuk matriks U dari entri bagian atas diagonal utama matriks A
U[lower.tri(A, diag=TRUE)]<-0
U
```

Selanjutya lakukan invers terhadap matriks $L$ menggunakn fungsi `solve()`.

```{r}
(Linv <- solve(L))
```

Tetapkan nilai estimasi awal dan nilai toleransi yang dikehendaki. Nilai toleransi pada proses ini ditetapkan sebesar $10^-7$.

```{r}
# tebakan awal nilai x
(x <- rep(0, length(b)))
```

Lakukan iterasi menggunakan Persamaan \@ref(eq:gaussseidel).

**Iterasi 1**

```{r}
(x1 <- Linv %*% (b - U %*% x))
```

```{r}
# akar jumlah kuadrat
sqrt(sum(x1-x)^2)
```

**Iterasi 2**

```{r}
(x2 <- Linv %*% (b - U %*% x1))
```

```{r}
# akar jumlah kuadrat
sqrt(sum(x2-x1)^2)
```

Iterasi terus dilakukan sampai dengan nilai akar jumlah kuadrat lebih kecil dari nilai toleransi. Setelah iterasi ke-7 diperoleh nilai vektor $x$ sebesar:

$$
x = \begin{bmatrix}
     2,425476     \\[0.3em]
     3,573016     \\[0.3em]
     1,925954
\end{bmatrix}
$$

----------------------------------------------

**Algoritma Iterasi Gauss-Seidel**

1. Masukkan matriks $A$, dan vektor $B$ beserta ukurannya $n$.
2. Lakukan dekomposisi LU, dimana matriks $L$ merupakan matriks segitiga bawah dengan nilai entri diagonal utama matriks $A$ dan bagian bawah diagonalnya dan matriks $U$ merupakan matriks segitiga atas dengan entri berasal dari elemen atas diagonal utama matriks $A$. Isi elemen lain yang tidak disebut pada kedua matriks tersebut dengan nol.
4. Tetapkan vektor $x$ estimasi.
5. Tetapkan nilai toleransi maksimum yang dapat diterima.
6. Lakukan iterasi menggunakan Persamaan \@ref(eq:gaussseidel).
7. Hitung akar jumlah kuadrat dari vektor $x^{n+1}$ dan vektor $x^n$.
8. Jadikan nilai $x^{n+1}$ sebagai nilai taksiran $x$ untuk iterasi berikutnya.
9. Hentikan proses iterasi jika telah memenuhi syarat yang ditampilkan pada Persamaan \@ref(eq:toleransi).

----------------------------------------------

Berdasarkan algoritma tersebut, kita dapat menyusun fungsi sebuah fungsi untuk melakukan iterasi Gauss-Seidel. Berikut sintaks yang digunakan:


```{r}
gauss_seidel <- function(a, b, tol=1e-7, maxiter=100){
  n <- length(b)
  iter <- 0
  
  
  L <- U <- a
  L[upper.tri(a, diag=FALSE)] <- 0
  U[lower.tri(a, diag=TRUE)] <- 0
  Linv <- solve(L)
  
  x <- rep(0,n)
  x_new <- rep(tol, n)
  
  while(sqrt(sum(x_new-x)^2)>tol){
            if(iter>maxiter){
              warning("iterasi maksimum tercapai")
              break
            }
            x <- x_new
            x_new <- Linv %*% (b - U %*% x)
            iter <- iter+1
  }
      return(list(X = x_new, iter=iter))
}
```

```{example, gaussseidelexm2}
Selesaikan sistem persamaan pada Contoh \@ref(exm:jacobiexm2) menggunakan fungsi `gauss_seidel()`!
```

**Jawab**:

Penyelesaiansistem persamaan linier tersebut menggunakan fungsi `gauss_seidel()` disajikan pada sintaks berikut:

```{r}
gauss_seidel(A,b)
```

## Studi Kasus {#studikasus}

Aljabar linier banyak diaplikasikan baik dalam bidang *engineering*, fisika, sampai dengan statistika. Pada *sub-chapter* ini penulis akan menjelaskan penerapan aljabar linier pada metode kuadrat terkecil dan aliran massa dalam reaktor. Untuk penerapan lainnya pembaca dapat membaca buku lainnya terkait aljabar linier.

### Metode Kuadrat Terkecil {#leastsquare}

Metode kuadrat terkecil merupakan salah satu aplikasi penerapan aljabar linier yang paling populer. Intuisi dibalik metode ini adalah bagaimana kita meminimalkan jarak antara sejumlah titik dengan garis regresi. Misalkan kita menggambarkan scatterplot antara dua buah variabel. Pola yang terbentuk dari plot tersebut adalah terjadi korelasi positif antara variabel pada sumbu $x$ dan sumbu $y$. Kita ingin menggambarkan garis regresi terbaik yang dapat menangkap seluruh pola tersebut. Garis regresi terbaik terjadi ketika jumlah kuadrat jarak antara titik observasi dan garis regresi yang terbentuk seminimal mungkin.

Untuk lebih memahaminya kita akan melakukan latihan menggunakan dataset `trees` yang berisi data hasil pengukuran kayu dari pohon yang ditebang. Pada dataset ini terdapat 31 observasi dan 3 buah kolom. Keterangan dari ketiga buah kolom tersebut adalah sebagai berikut:

* `Girth`: diameter pohon dalam satuan *inch*.
* `Height`: tinggi pohon dalam satuan *feet*.
* `Volume`: volume kayu dalam satuan *cubic feet*.

Untuk mengecek 6 observasi pertama dan struktur data, jalankan sintaks berikut:

```{r}
head(trees)
str(trees)
```

Scatterplot matriks sangat bagus untuk mengecek korelasi antar variabel dalam dataset tersebut. Berikut adalah sintaks untuk membuatnya:

```{r trees, LUfig,echo=FALSE, fig.cap='Scatterplot matriks dataset trees', tidy=FALSE, out.width='90%', fig.align='center', message=FALSE, warning=FALSE}
plot(trees)
```

Kita ingin membuat sebuah model linier untuk memprediksi `Volume` kayu berdasarkan variabel `Girth` dan `Heiht` atau volume sebagia fungsi dari variabel `Girth` dan `Heiht`. Kita dapat menuliskan relasi antara variabel volume sebagai fungsi dari variabel `Girth` dan `Heiht` menggunakan Persamaan \@ref(eq:trees).

\begin{equation}
Volume=\beta_{girth} Girth+\beta_{height}Height+\beta_0
 (\#eq:trees)
\end{equation}

dimana $\beta_0$ merupakan intersep persamaan regresi linier dan nilai $\beta$ lainnya merupakan koefisien dari variabel `Girth` dan `Heiht`. Variabel `Volume` disebut sebagai variabel respon, sedangkan variabel `Girth` dan `Heiht` disebut sebagai variabel prediktor.

Metode kuadrat terkecil berusaha memperoleh seluruh koefisien variabel dan intersep dari persamaan regresi linier. Berdasarkan yang telah penulis jelaskan garis regresi terbaik adalah garis yang memiliki nilai kuadrat terkecil jarak antara titik observasi dan garis regresi. Dasar dari metode kuadrat terkecil merupakan persamaan yang relatif sederhana yang ditunjukkan pada Persamaan \@ref(eq:trees2).

\begin{equation}
A^{T}A=A^{T}b
 (\#eq:trees2)
\end{equation}

dimana $b$ merupakan vektor dari variabel respon (`Volume`) dan matrik $A$ merupakan matriks variabel prediktor (variabel `Girth` dan `Heiht`). 

Untuk menginputkan intercept kedalam persamaan linier kita perlu menmabhakan satu kolom di awal matriks $A$ yang berisi nilai 1. Berikut adalah sintaks yang digunakan untuk membentuk matriks $A$:

```{r}
# membentuk matriks A
pred <- cbind(intercept=1, Girth=trees$Girth, Height=trees$Height)
head(A)
```

Langkah selanjutnya adalah membentuk matriks $b$. Berikut adalah sintaks yang digunakan:

```{r}
resp<- trees$Volume
head(resp)
```

Untuk memperoleh koefisien $\beta$, kita dapat mencarinya dengan cara menyelesaikan Persamaan \@ref(eq:trees2). Berikut adalah sintaks yang digunakan:

```{r}
A <- t(pred) %*% pred
b <- t(pred) %*% resp

Ab <- cbind(A,b)
(x <- gauss_jordan(Ab))
```

Berdasarkan hasil yang diperoleh, persamaan linier yang terbentuk disajikan pada Persamaan \@ref(eq:trees3).

\begin{equation}
Volume=4.7081605 Girth + 0.3392512 Height  -57.9876589
 (\#eq:trees3)
\end{equation}

Pembaca juga dapat menggunakan fungsi lain untuk memperoleh nilai koefisien tersebut, seperti: `lu_solve()`dan`solve()`. untuk fungsi `jacobi()` dan `gauss_seidel()`, kita harus pastikan syarat-syarat terkait metode tersebut. Berikut adalah contoh penyelesaian menggunakan sintaks lainnya:

```{r}
# metode LU
lu_solve(A,b)
```

```{r}
# fungsi solve()
solve(A,b)
```

`R` juga menyediakan fungsi untuk membentuk model regresi linier. Fungsi yang digunakan adalah `lm()`. Berikut sintaks yang digunakan untuk membentuk model linier menggunakan fungsi `lm()`:

```{r}
lm(Volume~Girth+Height, data=trees)
```

### Aliran Massa Dalam Reaktor {#reaktorkimia}

Pada *sub-chapter* ini penulis akan memberikan penerapan aljabar linier untuk menghitung konsentrasi suatu zat atau parameter lingkungan dalam reaktor yang saling terhubung. Pada contoh kasus kali ini diasumsikan terdapat lima buah reaktor yang saling terhubung satu sama lain sesuai Gambar \@ref(fig:reaktor). Debit air ($\frac{m^{3}}{detik}$) dan konsentrasi zat pencemar ($\frac{mg}{m^3}$) disajikan pula diagram alir tersebut. Diasumsikan kelima buah reaktor tersebut dalam kondisi *steady* dan volume reaktor diasumsikan sama. Kesetimbangan massa persatuan waktu dalam kondisi *steady* disajikan pada  Persamaan \@ref(eq:steady).

```{r reaktor,echo=FALSE, fig.cap='Aliran massa dalam reaktor.', tidy=FALSE, out.width='90%', fig.align='center', message=FALSE, warning=FALSE}
library(knitr)
img1_path <- "./images/reaktor.jpeg"
include_graphics(img1_path)

```

\begin{equation}
m_in=m_out
 (\#eq:steady)
\end{equation}

\begin{equation}
Q_{in}C_{in}= Q_{out}C_{out}
 (\#eq:steady2)
\end{equation}

Berdasarkan Gambar \@ref(fig:reaktor), dapat dibentuk lima buah sistem persamaan linier. Persamaan linier yang terbentuk disajikan sebagai berikut:

$$
\begin{matrix}
  6c_{1}-c_{3}=50 \\
  -3c_{1}+3c_{2}=0 \\
  -c_{2}+9c_{3}=160 \\
  -c_{2}-8c_{3}+11c_{4}-2c_{5}=0 \\
  -3c_{1}-c_{2}+4c_{5}=0
\end{matrix}
$$

Untuk menyelesaiakan sistem persamaan linier tersebut dan memperoleh nilai $c$ dari masing-masing reaktor, kiat perlu mengubahnya dulu kedalam bentuk matriks $Ax=b$. Berikut adalah matriks yang terbentuk:

\begin{equation*}
\begin{bmatrix}
      6 &  0 & -1 & 0  & 0    \\[0.3em]
     -3 &  3 & 0  & 0  & 0    \\[0.3em]
      0 & -1 & 9  & 0  & 0    \\[0.3em]
      0 & -1 & -8 & 11 & -2   \\[0.3em]
     -3 & -1 & 0  & 0  & 4
\end{bmatrix}
c = \begin{bmatrix}
     50     \\[0.3em]
     0      \\[0.3em]
     160    \\[0.3em]
     0      \\[0.3em]
     0
\end{bmatrix}
\end{equation*}

Kita akan menyelesaikannya dengan menggunakan metode elminasi Gauss-Jordan, dekomposisi LU, iterasi Jacobi, dan iterasi Gauss-Seidel. Untuk dapat menyelesaikannya menggunakan metode-metode tersebut pada `R`, kita perlu membentuk matriksnya terlebih dahulu:

```{r}
(A <- matrix(c(6,-3,0,0,-3,
              0,3,-1,-1,-1,
              -1,0,9,-8,0,
              0,0,0,11,0,
              0,0,0,-2,4),nrow=5))
(b <- c(50,0,160,0,0))
```

**Metode Eliminasi Gauss-Jordan**

```{r}
gauss_jordan(cbind(A,b))
```

**Metode Dekomposisi LU**

```{r}
lu_solve(A,b)
```

**Metode Iterasi Jacobi**

```{r}
jacobi(A,b, maxiter=100)
```

**Metode Iterasi Gauss-Seidel**

```{r}
gauss_seidel(A,b, maxiter=200)
```

Berdasarkan seluruh metode tersebut, diperoleh konsentrasi zat pencemar pada masing-masing reaktor adalah sebagai berikut:

$$
\begin{matrix}
  c_{1}=11,50943 \frac{mg}{m^3} \\
  c_{2}=11,50943 \frac{mg}{m^3} \\
  c_{3}=19,05660 \frac{mg}{m^3} \\
  c_{4}=16,99828 \frac{mg}{m^3} \\
  c_{5}=11.50943 \frac{mg}{m^3}
\end{matrix}
$$

## Referensi

1. Bloomfield, V.A. 2014. **Using R for Numerical Analysis in Science and Engineering**. CRC Press
2. Howard, J.P. 2017. **Computational Methods for Numerical Analysis with R**. CRC Press.
3. Kreyszig, E. 2011. **Advanced Engineering Mathematics, 10th Edition**. John Wiley & Sons.
4. Primartha, R. 2018. **Belajar Machine Learning Teori dan Praktik**. Penerbit Informatika : Bandung.
5. Sanjaya, M. 2015. **Metode Numerik Berbasis Phython**. Penerbit Gava Media: Yogyakarta.
6. Suparno, S. 2008. **Komputasi untuk Sains dan Teknik Edisi II**. Departemen Fisika-FMIPA Universitas Indonesia. 


## Latihan

1. Selesaikan sistem persamaan linier berikut menggunakan eliminasi Gauss!

$$
\begin{matrix}
  -4x+4y=-1 \\
  -2x+2y-3z=-3 \\
  3x+1y-3z=-3
\end{matrix}
$$

2. Carilah penyelesaian dari sistem persamaan linier soal no.1 menggunakan algoritma dekomposisi LU!
3. Tunjukan 5 iterasi pertama sistem persamaan linier berikut menggunakan algoritma Jacobi dan Gauss-Seidel!

$$
\begin{matrix}
  3x+2y-1z=-3 \\
  -3x-3y-3z=9 \\
  1y-1z=-1
\end{matrix}
$$

4. Gunakan fungsi `jacobi()` dan `gauss_seidel()` untuk menyelesaikan sistem persamaan linier pada soal no.4 dan tentukan metode mana yang paling cepat memperoleh penyelesaian? (**petunjuk**: gunakan fungsi `system.time()` dan jumlah iterasi yang diperlukan untuk memperoleh hasil yang konvergen)
5. Apakah yang terjadi jika kita menginputkan matriks segiempat $A$ kedalam fungsi `solve()` dan apa yang akan terjadi jika selanjutnya argumen pada fungsi tersebut juga menyertakan vektor $b$?
6. Dengan menggunakan dataset `mtcars` buatlah persamaan linier variabel `mpg` sebagai fungsi dari variabel `wt`, `hp`, dan `qsec` menggunakan algoritma dekomposisi LU? 






